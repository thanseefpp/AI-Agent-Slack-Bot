{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.callbacks import get_openai_callback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change Root Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load PDF Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"data/AI_Robotics.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n"
     ]
    }
   ],
   "source": [
    "loader = PyPDFLoader(file_path)\n",
    "docs = loader.load()\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data/AI_Robotics.pdf', 'page': 0}, page_content='Javier Andreu Perez, Fani Deligianni, Daniele Ravi and Guang-Zhong Yang  Artiﬁcial Intelligence and Robotics'),\n",
       " Document(metadata={'source': 'data/AI_Robotics.pdf', 'page': 1}, page_content='// Artificial Intelligence and Robotics\\n'),\n",
       " Document(metadata={'source': 'data/AI_Robotics.pdf', 'page': 2}, page_content='UKRAS.ORG\\nArtificial Intelligence and Robotics    //\\n'),\n",
       " Document(metadata={'source': 'data/AI_Robotics.pdf', 'page': 3}, page_content=\"// Artificial Intelligence and Robotics\\nWelcome to the UK-RAS White Paper \\nSeries on Robotics and Autonomous \\nSystems (RAS). This is one of the core \\nactivities of UK-RAS Network, funded by \\nthe Engineering and Physical Sciences \\nResearch Council (EPSRC). By bringing \\ntogether academic centres of excellence, \\nindustry, government, funding bodies and \\ncharities, the Network provides academic \\nleadership, expands collaboration with \\nindustry while integrating and coordinating \\nactivities at EPSRC funded RAS capital \\nfacilities, Centres for Doctoral Training and \\npartner universities.\\nThe recent successes of AI have captured \\nthe wildest imagination of both the scientific \\ncommunities and the general public. \\nRobotics and AI amplify human potentials, \\nincrease productivity and are moving from \\nsimple reasoning towards human-like cognitive abilities. Current AI technologies \\nare used in a set area of applications, \\nranging from healthcare, manufacturing, \\ntransport, energy, to financial services, \\nbanking, advertising, management \\nconsulting and government agencies. The \\nglobal AI market is around 260 billion USD \\nin 2016 and it is estimated to exceed 3 \\ntrillion by 2024. To understand the impact \\nof AI, it is important to draw lessons from \\nit's past successes and failures and this \\nwhite paper provides a comprehensive \\nexplanation of the evolution of AI, its current \\nstatus and future directions.\\nThe UK-RAS white papers are intended to \\nserve as a basis for discussing the future \\ntechnological roadmaps, engaging the \\nwider community and stakeholders, as well \\nas policy makers, in assessing the potential \\nsocial, economic and ethical/legal impact of RAS. It is our plan to provide annual \\nupdates for these white papers so your \\nfeedback is essential - whether it is to point \\nout inadvertent omissions of specific areas \\nof development that need to covered, or to \\nsuggest major future trends that deserve \\nfurther debate and in-depth analysis. \\nPlease direct all your feedback to white-\\npaper@ukras.org. We look forward to \\nhearing from you!\\n \\nProf Guang-Zhong Yang, CBE, FREng\\nChair, UK-RAS Network  FOREWORD\\nOn behalf of the UK-RAS Network, established to provide academic leadership, expand collaboration with industry \\nwhile integrating and coordinating activities at EPSRC funded RAS capital facilities, Centres for Doctoral Training \\nand partner universities.\\nDr. Javier Andreu Perez,  \\nThe Hamlyn Centre,  \\nImperial College LondonDr. Fani Deligianni,   \\nThe Hamlyn Centre,  \\nImperial College LondonDr. Daniele Ravi,  \\nThe Hamlyn Centre,  \\nImperial College LondonProf. Dr. Guang-Zhong Yang,  \\nThe Hamlyn Centre,  \\nImperial College London\"),\n",
       " Document(metadata={'source': 'data/AI_Robotics.pdf', 'page': 4}, page_content='Artificial Intelligence and Robotics  //\\nIn 2016, Artificial Intelligence (AI) celebrated \\nits 60th anniversary of the Dartmouth \\nWorkshop, which marked the beginning \\nof AI being recognised as an academic \\ndiscipline. One year on, the pace of AI has \\ncaptured the wildest imagination of both the \\nscientific community and the general public. \\nThe term AI now encompasses the whole \\nconceptualisation of a machine that is \\nintelligent in terms of both operational and \\nsocial consequences. With the prediction \\nof the AI market to reach 3 trillion by 2024, \\nboth industry and government funding \\nbodies are investing heavily in AI and \\nrobotics. As the availability of information \\naround us grows, humans will rely more \\nand more on AI systems to live, to work, \\nand to entertain. Given increased accuracy \\nand sophistication of AI systems, they will \\nbe used in an increasingly diverse range of \\nsectors including finance, pharmaceuticals, \\nenergy, manufacturing, education, transport \\nand public services. It has been predicted \\nthat the next stage of AI is the era of \\naugmented intelligence. Ubiquitous sensing \\nsystems and wearable technologies are \\ndriving towards intelligent embedded systems that will form a natural extension of \\nhuman beings and our physical abilities. Will \\nAI trigger a transformation leading to super-\\nintelligence that would surpass all human \\nintelligence?\\nThis white paper explains the origin of AI, \\nits evolution in the last 60 years, as well \\nas related subfields including machine \\nlearning, computer vision and the rise of \\ndeep learning. It provides a rational view \\nof the different seasons of AI and how to \\nlearn from these ‘boom-and-bust’ cycles \\nto ensure the current progresses are \\nsustainable and here to stay. Along with \\nthe unprecedented enthusiasm of AI, there \\nare also fears about the impact of the \\ntechnology on our society. A clear strategy \\nis required to consider the associated \\nethical and legal challenges to ensure that \\nsociety as a whole will benefit from the \\nevolution of AI and its potential negative \\nimpact is mitigated from early on. To this \\nend, the paper outlines the ethical and legal \\nissues of AI, which encompass privacy, \\njobs, legal responsibility, civil rights, and \\nwrongful use of AI for military purposes. \\nThe paper concludes by providing a set of recommendations to the research \\ncommunity, industry, government agencies \\nand policy makers. \\nTo sustain the current progress of AI, it is \\nimportant to understand what is science \\nfiction and what is practical reality. A \\nrational and harmonic interaction is required \\nbetween application specific projects \\nand visionary research ideas. Neither the \\nunrealistic enthusiasm nor the unjustified \\nfears of AI should hinder its progress. \\nThey should be used to motivate the \\ndevelopment of a systematic framework \\non which the future of AI will flourish. \\nWith sustained funding and responsible \\ninvestment, AI is set to transform the \\nfuture of our society - our life, our living \\nenvironment and our economy.EXECUTIVE SUMMARY \\n'),\n",
       " Document(metadata={'source': 'data/AI_Robotics.pdf', 'page': 5}, page_content='// Artificial Intelligence and Robotics\\nRobotics and AI augment and amplify human \\npotentials, increase productivity and are moving \\nfrom simple reasoning towards human-like cognitive \\nabilities. To understand the impact of AI, it is important \\nto draw lessons from the past successes and \\nfailures, as well as to anticipate its future directions \\nand potential legal, ethical and socio-economic \\nimplications.”\\n'),\n",
       " Document(metadata={'source': 'data/AI_Robotics.pdf', 'page': 6}, page_content='Artificial Intelligence and Robotics  //\\nCONTENTS\\n1 Introduction 2\\n2 The birth and boom of AI 3\\n3 Questioning the impact of AI  7\\n4 A closer look at the evolution of AI 9 \\n 4.1 Seasons of AI 9 \\n 4.2 Influence of funding 9 \\n 4.3 Publication vs Patenting 10\\n5 Financial impact of AI 12\\n6 Subfields and technologies that underpinnings AI 18\\n7 The rise of Deep Learning: rethinking the machine learning pipeline 19\\n8 Hardware for AI 22\\n9 Robotics and AI 24\\n10 Programming languages for AI  27\\n11 Impact of Machine Vision  32\\n12 Artificial Intelligence and the Big Brain  36\\n13  Ethical and legal questions of AI  39 \\n 13.1  Ethical issues in AI  39 \\n 13.2  Legal issues and questions of AI  40\\n14 Limitations and opportunities of AI  41\\n15 Conclusion and recommendations  43\\nReferences 44'),\n",
       " Document(metadata={'source': 'data/AI_Robotics.pdf', 'page': 7}, page_content='With increased capabilities and sophistication of AI \\nsystems, they will be used in more diverse ranges of \\nsectors including finance, pharmaceuticals, energy, \\nmanufacturing, education, transport and public services. \\nThe next stage of AI is the era of augmented intelligence, \\nseamlessly linking human and machine together.\\n1 // Artificial Intelligence and Robotics\\n'),\n",
       " Document(metadata={'source': 'data/AI_Robotics.pdf', 'page': 8}, page_content='Artificial Intelligence and Robotics  // 2\\n1. INTRODUCTION\\nArtificial Intelligence (AI) is a commonly employed appellation \\nto refer to the field of science aimed at providing machines \\nwith the capacity of performing functions such as logic, \\nreasoning, planning, learning, and perception. Despite the \\nreference to “machines” in this definition, the latter could \\nbe applied to “any type of living intelligence”. Likewise, the \\nmeaning of intelligence, as it is found in primates and other \\nexceptional animals for example, it can be extended to \\ninclude an interleaved set of capacities, including creativity, \\nemotional knowledge, and self-awareness.\\nThe term AI was closely associated with the field of \\n“symbolic AI”, which was popular until the end of the 1980s. \\nIn order to overcome some of the limitations of symbolic AI, \\nsubsymbolic methodologies such as neural networks, fuzzy \\nsystems, evolutionary computation and other computational \\nmodels started gaining popularity, leading to the term \\n“computational intelligence” emerging as a subfield of AI.\\nNowadays, the term AI encompasses the whole \\nconceptualisation of a machine that is intelligent in terms \\nof both operational and social consequences. A practical \\ndefinition used is one proposed by Russell and Norvig: \\n“Artificial Intelligence is the study of human intelligence \\nand actions replicated artificially, such that the resultant \\nbears to its design a reasonable level of rationality” [1]. This \\ndefinition can be further refined by stipulating that the level \\nof rationality may even supersede humans, for specific and \\nwell-defined tasks. \\nCurrent AI technologies are used in online advertising, \\ndriving, aviation, medicine and personal assistance image \\nrecognition. The recent success of AI has captured the \\nimagination of both the scientific community and the public. \\nAn example of this is vehicles equipped with an automatic \\nsteering system, also known as autonomous cars. Each \\nvehicle is equipped with a series of lidar sensors and \\ncameras which enable recognition of its three-dimensional \\nenvironment and provides the ability to make intelligent decisions on maneuvers in variable, real-traffic road \\nconditions. Another example is the Alpha-Go, developed by \\nGoogle Deepmind, to play the board game Go. Last year, \\nAlpha-Go defeated the Korean grandmaster Lee Sedol, \\nbecoming the first machine to beat a professional player and \\nrecently it went on to win against the current world number \\none, Ke Jie, in China. The number of possible games in Go \\nis estimated to be 10761 and given the extreme complexity \\nof the game, most AI researchers believed it would be \\nyears before this could happen. This has led to both the \\nexcitement and fear in many that AI will surpass humans in \\nall the fields it marches into. \\nHowever, current AI technologies are limited to very specific \\napplications. One limitation of AI, for example, is the lack of \\n“common sense”; the ability to judge information beyond \\nits acquired knowledge. A recent example is that of the AI \\nrobot Tay developed by Microsoft and designed for making \\nconversations on social networks. It had to be disconnected \\nshortly after its launch because it was not able to distinguish \\nbetween positive and negative human interaction. AI is also \\nlimited in terms of emotional intelligence. AI can only detect \\nbasic human emotional states such as anger, joy, sadness, \\nfear, pain, stress and neutrality. Emotional intelligence is one \\nof the next frontiers of higher levels of personalisation. \\nTrue and complete AI does not yet exist. At this level, AI will \\nmimic human cognition to a point that it will enable the ability \\nto dream, think, feel emotions and have own goals. Although \\nthere is no evidence yet this kind of true AI could exist before \\n2050, nevertheless the computer science principles driving \\nAI forward, are rapidly advancing and it is important to \\nassess its impact, not only from a technological standpoint, \\nbut also from a social, ethical and legal perspective. '),\n",
       " Document(metadata={'source': 'data/AI_Robotics.pdf', 'page': 9}, page_content='Since 2000, a third renaissance of the \\nconnectionism paradigm arrived with the dawn \\nof Big Data, propelled by the rapid adoption of \\nthe internet and mobile communication.\\n3 // Artificial Intelligence and Robotics\\n2. THE BIRTH AND BOOM OF AI\\nThe birth of the computer took place when the first \\ncalculator machines were developed, from the mechanical \\ncalculator of Babbage, to the electromechanical calculator \\nof Torres-Quevedo. The dawn of automata theory can \\nbe traced back to World War II with what was known as \\nthe “codebreakers”. The amount of operations required \\nto decode the German trigrams of the Enigma machine, \\nwithout knowing the rotor’s position, proved to be too \\nchallenging to be solved manually. The inclusion of automata \\ntheory in computing conceived the first logical machines to \\naccount for operations such as generating, codifying, storing \\nand using information. Indeed, these four tasks are the basic \\noperations of information processing performed by humans. \\nThe pioneering work by Ramón y Cajal marked the birth of \\nneuroscience, although many neurological structures and \\nstimulus responses were already known and studied before \\nhim. For the first time in history the concept of “neuron” \\nwas proposed. McClulloch and Pitts further developed a \\nconnection between automata theory and neuroscience, \\nproposing the first artificial neuron which, years later, gave \\nrise to the first computational intelligence algorithm, namely \\n“the perceptron”. This idea generated great interest among \\nprominent scientists of the time, such as Von Neumann, \\nwho was the pioneer of modern computers and set the \\nfoundation for the connectionism movement. 1956 – \\nwhen the term AI was first coined.\\n \\nThe Dartmouth Conference of 1956 was organized \\nby Marvin Minsky, John McCarthy and two senior \\nscientists, Claude Shannon and Nathan Rochester \\nof IBM. At this conference, the expression \\n“Artificial Intelligence” was first coined as the title \\nof the field. The Dartmouth conference triggered a \\nnew era of discovery and unrestrained conquests \\nof new knowledge. The computer programmes \\ndeveloped at the time are considered by most \\nas simply \"extraordinary\"; computers solve \\nalgebraic problems, demonstrate theorems in \\ngeometry and learnt to speak English. At that \\ntime, many didn’t believe that such \"intelligent\" \\nbehavior was possible in machines. Researchers \\ndisplayed a great deal of optimism both in private \\nand in scientific publications. They predicted \\nthat a completely intelligent machine would be \\nbuilt in the next 20 years. Government agencies, \\nsuch as the US Defence and Research Project \\nAgency (DARPA), were investing heavily in this \\nnew area. It is worth mentioning, that some of \\nthe aforementioned scientists, as well as major \\nlaboratories of the time, such as Los Alamos \\n(Nuevo Mexico, USA), had strong connections with \\nthe army and this link had a prominent influence, \\nas the work at Bletchley Park (Milton Keynes, \\nUK) had, over the course of WWII, as did political \\nconflicts like the Cold War in AI innovation. '),\n",
       " Document(metadata={'source': 'data/AI_Robotics.pdf', 'page': 10}, page_content='Artificial Intelligence and Robotics  // 4\\nIn 1971, DARPA funded a consortium of leading laboratories \\nin the field of speech recognition. The project had the \\nambitious goal of creating a fully functional speech \\nrecognition system with a large vocabulary. In the middle \\nof the 1970s, the field of AI endured fierce criticism and \\nbudgetary restrictions, as AI research development did not \\nmatch the overwhelming expectations of researchers.. When \\npromised results did not materialize, investment in AI eroded. \\nFollowing disappointing results, DARPA withdrew funding in \\nspeech recognition and this, coupled with other events such \\nas the failure of machine translation, the abandonment of \\nconnectionism and the Lighthill report, marked the first winter \\nof AI [2]. During this period, connectionism stagnated for \\nthe next 10 years following a devastating critique by Marvin \\nMinksy on perceptrons [3]. \\nFrom 1980 until 1987, AI programmes, called “expert \\nsystems”, were adopted by companies and knowledge \\nacquisition become the central focus of AI research. At the \\nsame time, the Japanese government launched a massive \\nfunding program on AI, with its fifth-generation computers \\ninitiative. Connectionism was also revived by the work of \\nJohn Hopfield [4] and David Rumelhart [5].\\nAI researchers who had experienced the first backlash in \\n1974, were sceptical about the reignited enthusiasms of \\nexpert systems and sadly their fears were well founded. \\nThe first sign of a changing tide was with the collapse of \\nthe AI computer hardware market in 1987. Apple and IBM \\ndesktops had gradually improved their speed and power \\nand in 1987 they were more powerful than the best LISP \\nmachines on the market. Overnight however, the industry collapsed and billions of dollars were lost. The difficulty of \\nupdating and reprograming the expert systems, in addition \\nto the high maintenance costs, led to the second AI winter. \\nInvestment in AI dropped and DARPA stopped its strategic \\ncomputing initiative, claiming AI was no longer the “latest \\nmode”. Japan also stopped funding its fifth-generation \\ncomputer program as the proposed goals were not \\nachieved.\\nIn the 1990s, the new concept of “intelligent agent” emerged \\n[6]. An agent is a system that perceives its environment \\nand undertakes actions that maximize its chances of being \\nsuccessful. The concept of agents conveys, for the first \\ntime, the idea of intelligent units working collaboratively with \\na common objective. This new paradigm was intended to \\nmimic how humans work collectively in groups, organizations \\nand/or societies. Intelligent agents proved to be a more \\npolyvalent concept of intelligence. In the late 1990s, fields \\nsuch as statistical learning from several perspectives \\nincluding probabilistic, frequentist and possibilistic (fuzzy \\nlogic) approaches, were linked to AI to deal with the \\nuncertainty of decisions. This brought a new wave of \\nsuccessful applications for AI, beyond what expert  \\nsystems had achieved during the 1980s. These new ways'),\n",
       " Document(metadata={'source': 'data/AI_Robotics.pdf', 'page': 11}, page_content='5 // Artificial Intelligence and Robotics\\nof reasoning were more suited to cope with the uncertainty \\nof intelligent agent states and perceptions and had its major \\nimpact in the field of control. During this time, high-speed \\ntrains controlled by fuzzy logic, were developed [7] as were \\nmany other industrial applications (e.g. factory valves, gas \\nand petrol tanks surveillance, automatic gear transmission \\nsystems and reactor control in power plants) as well as \\nhousehold appliances with advanced levels of intelligence \\n(e.g. air-conditioners, heating systems, cookers and vacuum-\\ncleaners). These were different to the expert systems in \\n1980s; the modelling of the inference system for the task, \\nachieved through learning, gave rise to the field of Machine \\nLearning. Nevertheless, although machine reasoning \\nexhibited good performance, there was still an engineering \\nrequirement to digest the input space into a new source, so that intelligence could reason more effectively. Since 2000, \\na third renaissance of the connectionism paradigm arrived \\nwith the dawn of Big Data, propelled by the rapid adoption \\nof the Internet and mobile communication. Neural networks \\nwere once more considered, particularly in the role they \\nplayed in enhancing perceptual intelligence and eliminating \\nthe necessity of feature engineering. Great advances were \\nalso made in computer vision, improving visual perception, \\nincreasing the capabilities of intelligent agents and robots \\nin performing more complex tasks, combined with visual \\npattern recognition. All these paved the way to new AI \\nchallenges such as, speech recognition, natural language \\nprocessing, and self-driving cars. A timeline of key highlights \\nin the history of AI is shown in Figure 1.Figure 1.\\nA timeline highlighting some of the most relevant events of AI since 1950. The blue boxes represent events that have had a positive impact on \\nthe development of AI. In contrast, those with a negative impact are shown in red and reflect the low points in the evolution of the field, i.e. the \\nso-called ”winters” of AI.\\n1950 1954 1958 1962 1966 1970 1974 1980 1984 1988 1992 1996 2000 2004 2008 2012 2016\\n• Turing test\\n• Assimov’s \\n   three laws\\n• Dartmouth    Conference\\n• Rosenblatt’s \\n   Preceptron\\n• Bayesian methods\\n• Unimation \\n   robot for GM\\n• Rise of LISP\\n• Negative report \\n   on machine    translation\\n• MacHack (Chess)\\n• Dendral expert \\n   systems \\n• Perceptron    book (Minsky    and Papert’s)\\n• DARPA cuts    in academic    research on AI\\n• First robot cars   (Dickmanns)\\n• Collapse LISP machines   \\n• End US strategy \\n   computing program\\n• Experts systems    all-time low\\n• IBM’s Deep Blue\\n• First Robocup\\n• IBM Watson    won Jeopardy    20011\\n• HRP-2    humanoid robot\\n• Parallel    Computing\\n \\n• MYCIN Medical    decision support    syste \\n • SHRDLU Language \\n   understanding   and robotics\\n• First game playing\\n• IBM (Arthur Samuel)\\n• Man-computer \\n   Symbiosis   \\n• Semantic nets \\n   (Masterman)\\n• Birth of    PROLOG\\n• BKG back-   gammon AI \\n \\n      \\n• ELIZA (interactive \\n   dialogue,    ARPANET)\\n• Locomotion,    problem solving    (Shakey, Standford)\\n• Minsky’s AI Agents\\n• Brooks’s Nouvelle AI\\n • Marvin Minsky’s    frames, schemes    and semantic links\\n• David Marr’s \\n   visual perception \\n• Neural networks    Backpropagation\\n• iRobot’s    Roomba\\n• Microsoft    Kinect\\n • Google’s    Alpha Go• Blue Brain\\n• Berners-Lee’s    Semantic Web\\n• ALVINN\\n• TD-Gammon    & reinforcement    learning\\n• DARPA’s DART• MIT’s Cog\\n• Chinook checkers AI\\n• Birth of   LISP\\n• Honda’s    ASIMO\\n• First web    crawlers\\n• Robopets\\n• DARPA grand    challenge\\n • self-driving    cars\\n'),\n",
       " Document(metadata={'source': 'data/AI_Robotics.pdf', 'page': 12}, page_content='Artificial Intelligence and Robotics  // 6\\nWeak and Strong AI\\n \\nWhen defining the capacity of AI, this is frequently \\ncategorised in terms of weak or strong AI. \\nWeak AI (narrow AI) is one intended to reproduce an \\nobserved behaviour as accurately as possible. It can \\ncarry out a task for which they have been precision-\\ntrained. Such AI systems can become extremely efficient \\nin their own field but lack generalisational ability. Most \\nexisting intelligent systems that use machine learning, \\npattern recognition, data mining or natural language \\nprocessing are examples of weak AI. Intelligent systems, \\npowered with weak AI include recommender systems, \\nspam filters, self-driving cars, and industrial robots.\\nStrong AI is usually described as an intelligent system \\nendowed with real consciousness and is able to think   \\n \\nand reason in the same way as a human being. A \\nstrong AI can, not only assimilate information like a \\nweak AI, but also modify its own functioning, i.e. is able \\nto autonomously reprogram the AI to perform general \\nintelligent tasks. These processes are regulated by \\nhuman-like cognitive abilities including consciousness, \\nsentience, sapience and self-awareness. Efforts intending \\nto generate a strong AI have focused on whole brain \\nsimulations, however this approach has received \\ncriticism, as intelligence cannot be simply explained as a \\nbiological process emanating from a single organ but is a \\ncomplex coalescence of effects and interactions between \\nthe intelligent being and its environment, encompassing a \\nseries of diverse ways via interlinked biological process. \\n1950 1954 1958 1962 1966 1970 1974 1980 1984 1988 1992 1996 2000 2004 2008 2012 2016\\n• Turing test\\n• Assimov’s \\n   three laws\\n• Dartmouth \\n   Conference\\n• Rosenblatt’s \\n   Preceptron\\n• Bayesian methods\\n• Unimation \\n   robot for GM\\n• Rise of LISP\\n• Negative report \\n   on machine    translation\\n• MacHack (Chess)\\n• Dendral expert \\n   systems \\n• Perceptron \\n   book (Minsky    and Papert’s)\\n• DARPA cuts    in academic    research on AI\\n• First robot cars\\n   (Dickmanns)\\n• Collapse LISP machines   \\n• End US strategy \\n   computing program\\n• Experts systems    all-time low\\n• IBM’s Deep Blue\\n• First Robocup\\n• IBM Watson \\n   won Jeopardy    20011\\n• HRP-2    humanoid robot\\n• Parallel    Computing\\n \\n• MYCIN Medical    decision support    syste \\n • SHRDLU Language \\n   understanding   and robotics\\n• First game playing\\n• IBM (Arthur Samuel)\\n• Man-computer    Symbiosis   \\n• Semantic nets \\n   (Masterman)\\n• Birth of    PROLOG\\n• BKG back-   gammon AI \\n \\n      \\n• ELIZA (interactive    dialogue,    ARPANET)\\n• Locomotion,    problem solving    (Shakey, Standford)\\n• Minsky’s AI Agents\\n• Brooks’s Nouvelle AI\\n • Marvin Minsky’s \\n   frames, schemes    and semantic links\\n• David Marr’s \\n   visual perception \\n• Neural networks \\n   Backpropagation\\n• iRobot’s    Roomba\\n• Microsoft    Kinect\\n • Google’s    Alpha Go• Blue Brain\\n• Berners-Lee’s    Semantic Web\\n• ALVINN\\n• TD-Gammon    & reinforcement    learning\\n• DARPA’s DART• MIT’s Cog\\n• Chinook checkers AI\\n• Birth of\\n   LISP\\n• Honda’s \\n   ASIMO\\n• First web    crawlers\\n• Robopets\\n• DARPA grand    challenge\\n • self-driving    cars\\n'),\n",
       " Document(metadata={'source': 'data/AI_Robotics.pdf', 'page': 13}, page_content='7 // Artificial Intelligence and Robotics\\nGiven the exponential rise of interest in AI, experts have \\ncalled for major studies on the impact of AI on our society, \\nnot only in technological but also in legal, ethical and socio-\\neconomic areas. This response also includes the speculation \\nthat autonomous super artificial intelligence may one day \\nsupersede the cognitive capabilities of humans. This future \\nscenario is usually known in AI forums as the “AI singularity” \\n[8]. This is commonly defined as the ability of machines to \\nbuild better machines by themselves. This futuristic scenario \\nhas been questioned and is received with scepticism by \\nmany experts. Today’s AI researchers are more focused on \\ndeveloping systems that are very good at tasks in a narrow \\nrange of applications. This focus is at odds with the idea of \\nthe pursuit of a super generic AI system that could mimic all \\ndifferent cognitive abilities related to human intelligence such \\nas self-awareness and emotional knowledge. In addition \\nto this debate, about AI development and the status of our \\nhegemony as the most intelligent species on the planet, \\nfurther societal concerns have been raised. For example, the \\nAI100 (One Hundred Year Study on Artificial Intelligence) a \\ncommittee led by Stanford University, defined 18 topics of \\nimportance for AI [9]. Although these are not exhaustive nor \\ndefinitive, it sets forth the range of topics that need to be \\nstudied, for the potential impact of AI and stresses that there \\nare a number of concerns to be addressed. Many similar \\nassessments have been performed and they each outline \\nsimilar concerns related to the wider adoption of  \\nAI technology.The 18 topics covered by the AI100  \\nTechnical trends and surprises:  This topic aims at \\nforecasting the future advances and competencies of AI \\ntechnologies in the near future. Observatories of the trend \\nand impact of AI should be created, helping to plan the \\nsetting of AI in specific sectors, and preparing the necessary \\nregulation to smooth its introduction.\\nKey opportunities for AI:  How advances in AI can help to \\ntransform the quality of societal services such as health, \\neducation, management and government, covering not just \\nthe economic benefits but also the social advantages and \\nimpact.\\nDelays with translating AI advances into real-world values:  \\nThe pace of translating AI into real world applications is \\ncurrently driven by potential economic prospects [10]. It is \\nnecessary to take measures to foster a rapid translation of \\nthose potential applications of AI that can improve or solve a \\ncritical need of our society, such as those that can save lives \\nor greatly improve the organisation of social services, even \\nthough their economic exploitation is not yet assured.\\nPrivacy and machine intelligence:  Personal data and \\nprivacy is a major issue to consider and it is important \\nto envisage and prepare the regulatory, legal and policy \\nframeworks related to the sharing of personal data in \\ndeveloping AI systems. \\nDemocracy and freedom:  In addition to privacy, ethical \\nquestions with respect to the stealth use of AI for \\nunscrupulous applications must be considered. The use  \\nof AI should not be at the expense of limiting or influencing \\nthe democracy and the freedom of people. \\nLaw: This considers the implications of relevant laws and \\nregulations. First, to identify which aspects of AI require \\nlegal assessment and what actions should be undertaken \\nto ensure law enforcement for AI services. It should also \\nprovide frameworks and guidelines about how to adhere to \\nthe approved laws and policies.\\nEthics:  By the time AI is deployed into real world \\napplications there are ethical concerns referring to their \\ninteraction with the world. What uses of AI should be \\nconsidered unethical? How should this be disclosed? 3. QUESTIONING THE IMPACT OF AI'),\n",
       " Document(metadata={'source': 'data/AI_Robotics.pdf', 'page': 14}, page_content='Artificial Intelligence and Robotics  // 8\\nEconomics:  The economic implications of AI on jobs \\nshould be monitored and forecasted such that policies can \\nbe implemented to direct our future generation into jobs \\nthat will not be soon overtaken by machines. The use of \\nsophisticated AI in the financial markets could potentially \\ncause volatilities and it is necessary to assess the influence \\nAI systems may have on financial markets.\\nAI and warfare:  AI has been employed for military \\napplications for more than a decade. Robot snipers and \\nturrets have been developed for military purposes [11]. \\nIntelligent weapons have increasing levels of autonomy \\nand there is a need for developing new conventions and \\ninternational agreements to define a set of secure boundaries \\nof the use of AI in weaponry and warfare.\\nCriminal uses of AI:  Implementations of AI into malware \\nare becoming more sophisticated thus the chances of \\nstealing personal information from infected devices are \\ngetting higher. Malware can be more difficult to detect as \\nevasion techniques by computer viruses and worms may \\nleverage highly sophisticated AI techniques [12, 13]. Another \\nexample is the use of drones and their potential to fall into \\nthe hands of terrorists the consequence of which  would be \\ndevastating. \\nCollaboration with machines:  Humans and robots need \\nto work together and it is pertinent to envisage in which \\nscenarios collaboration is critical and how to perform this \\ncollaboration safely. Accidents by robots working side by \\nside with people had happened before [14] and robotic and \\nautonomous systems development should focus on not only \\nenhanced task precision but in also being able to understand \\nthe environment and human intention.\\nAI and human cognition:  AI has the potential for enhancing \\nhuman cognitive abilities. Some relevant research disciplines \\nwith this objective are sensor informatics and human-\\ncomputer interfaces. Apart from applications to rehabilitation \\nand assisted living, they are also used in surgery [15] and \\nair traffic control [16]. Cortical implants are increasingly used \\nfor controlling prosthesis, our memory and reasoning are \\nincreasingly relying on machines and the associated health, \\nsafety and ethical impacts must be addressed.Safety and Autonomy: For the safe operation of intelligent, \\nautonomous systems, formal verification tools should be \\ndeveloped to assess their safety operation. Validation can \\nbe focused on the reasoning process and verifying whether \\nthe knowledge base of an intelligent system is correct [17] \\nand also making sure that the formulation of the intelligent \\nbehaviour will be within safety boundaries [18].\\nLoss of control of AI systems:  The potential of AI being \\nindependent from human control is a major concern. Studies \\nshould be promoted to address this concern both from the \\ntechnological standpoint and the relevant framework for \\ngoverning the responsible development of AI. \\nPsychology of people and smart machines:  More research \\nshould be undertaken to obtain detailed knowledge about \\nthe opinions and concerns people have, in the wider usage \\nof smart machines in societies. Additionally, in the design of \\nintelligent systems, understanding people’s preferences is \\nimportant for improving their acceptability [19, 20].\\nCommunication, understanding and outreach:  \\nCommunication and educational strategies must be \\ndeveloped to embrace AI technologies in our society. \\nThese strategies must be formulated in ways that are \\nunderstandable and accessible by non-experts and the \\ngeneral public. \\nNeuroscience and AI:  Neuroscience and AI can develop \\ntogether. Neuroscience plays an important role for guiding \\nresearch in AI and with new advances in high performance \\ncomputing, there are also new opportunities to study the \\nbrain through computational models and simulations in order \\nto investigate new hypotheses [21].\\nAI and philosophy of mind:  When AI can experience a level \\nof consciousness and self-awareness, there will be a need \\nto understand the inner world of the psychology of machines \\nand their subjectivity of consciousness.'),\n",
       " Document(metadata={'source': 'data/AI_Robotics.pdf', 'page': 15}, page_content='9 // Artificial Intelligence and Robotics\\nThe evolution of AI to date, has endured several cycles of \\noptimism (springs) and pessimism or negativism (winters): \\n•  Birth of AI (1952-1956): Before the term AI was coined, \\nthere were already advances in cybernetics and neural \\nnetworks, which started to attract the attention of both \\nthe scientific communities and the public. The Dartmouth \\nConference (1956) was the result of this increasing \\ninterest and gave rise to the following golden years of AI \\nwith high levels of optimism in the field. \\n•  First spring (1956-1974): Computers of the time could \\nsolve algebra and geometric problems, as well as speak \\nEnglish. Advances were qualified as “impressive” and \\nthere was a general atmosphere of optimism in the field. \\nResearchers in the area estimated that a fully intelligent \\nmachine would be built in the following 20 years. \\n•  First winter (1974-1980): The winter started when \\nthe public and media questioned the promises of AI. \\nResearchers were caught in a spiral of exaggerated \\nclaims and forecasts but the limitations the technology \\nposed at the time were inviolable. An abrupt ending of \\nfunding by major agencies such as DARPA, the National \\nResearch Council and the British Government, led to the \\nfirst winter of AI. \\n•  Second Spring (1980-1987): Expert systems were \\ndeveloped to solve problems of a specific domain by \\nusing logical rules derived from experts. There was \\nalso a revival of connectionism and neural networks for \\ncharacter or speech recognition. This period is known as \\nthe second spring of AI. \\n•  Second winter (1987-1993): Specialised machines for \\nrunning expert systems were displaced by new desktop \\ncomputers. Consequently some companies, that \\nproduced expert systems, went into bankruptcy. This led \\nto a new wave of pessimism ending the funding programs \\ninitiated during the previous spring. •  In the background (1997-2000): From 1997 to 2000, \\nthe field of AI was progressing behind the scenes, as \\nno further multi-million programs were announced. \\nDespite the lack of major funding the area continued to \\nprogress, as increased computer power and resources \\nwere developed. New applications in specific areas were \\ndeveloped and the concept of “machine learning” started \\nto become the cornerstone of AI.\\n•  Third spring (2000-Present): Since 2000, with the \\nsuccess of the Internet and web, the Big Data revolution \\nstarted to take off along with newly emerged areas such \\nas Deep Learning. This new period is known as the third \\nspring of AI and for time being, it looks like it is here to \\nstay. Some have even started to predict the imminent \\narrival of singularity - an intelligence explosion resulting in \\na powerful super-intelligence that will eventually surpass \\nhuman intelligence. Is this possible?\\n \\n4.2 INFLUENCE OF FUNDING     \\nGovernment organisations and the public sector are \\ninvesting millions to boost artificial intelligence research.  \\nFor example, the National Research Foundation of \\nSingapore is investing $150 million into a new national \\nprogramme in AI. In the UK alone, £270 million is being \\ninvested from 2017 to 2018 to boost science, research \\nand innovation, via the Government’s new industrial \\nstrategy and a further funding of £4.7 billion is planned \\nby 2021 [22]. This timely investment will put UK in the \\ntechnological lead among the best in the world and ensure \\nthat UK technological innovations can compete. Recent AI \\ndevelopments have triggered major investment across all \\nsectors including financial services, banking, marketing and \\nadvertising, in hospitals and government administration. \\nIn fact software and information technology services have \\nmore than a 30% share in all AI investments worldwide as of \\n2016, whereas Internet and telecommunication companies \\nfollow with 9% and 4%, respectively [23]. 4. A CLOSER LOOK AT THE EVOLUTION OF AI\\n4.1  SEASONS OF AI'),\n",
       " Document(metadata={'source': 'data/AI_Robotics.pdf', 'page': 16}, page_content=\"Figure 2 \\nEvolution of filed patents in AI across countries for five-year periods since 1995 to present day.\\n1 https://arxiv.org/\\n2 vixra.org\\nArtificial Intelligence and Robotics  // 10\\nIt is also important to note that the funding in AI safety, \\nethics and strategy/policy has almost doubled in the last \\nthree years [24]. Apart from non-profit organisations, \\nsuch as the Future of Life Institute (FLI) and the Machine \\nIntelligence Research Institute (MIRI), other centres, such \\nas the Centre for Human-Compatible AI and Centre for the \\nFuture of Intelligence, have emerged and they, along with key \\ntechnological firms, invested a total of $6.6 million in 2016. \\n \\n4.3 PUBLICATION VERSUS PATENTING \\nIn terms of international output in publications and patents, \\nthere has been a shift of predominant countries influencing \\nthe field of AI. In 1995 USA and Japan were the two leading \\ncountries in the field of AI patents but this has now shifted to Asia, with China becoming a major player. Since 2010 China \\nand USA have led the way in both scientific publications and \\nin the filing of patents. Other emerging economies, such as \\nIndia and Brazil, are also rapidly rising.\\nRecently, there has been a shift relocation of many academic \\nprofessionals in AI to the industrial sector. The world's largest \\ntechnology companies have hired several entire research \\nteams previously in universities. These corporations have \\nopted for the publication of pre-prints (ArXiv1 or viXra2) and \\nother non-citable documents, instead of using conventional \\nacademic methods of peer-review. This has become an \\nincreasing trend. The reason for this is that it allows the \\nprioritisation of claim imprinting without the delay of a peer-\\nreview process.\"),\n",
       " Document(metadata={'source': 'data/AI_Robotics.pdf', 'page': 17}, page_content='Figure 3 \\nEvolution of citable articles in AI across countries for five-year periods since 1995 to present day.\\nTime series (yearly) Database Publisher Query\\nNumber of publications \\nof AI by computational \\nintelligence methodsWeb of Science Thomson Reuters  [25] {(“artificial neural networks”) \\nOR   (“evolutionary computation”) \\nOR (“evolutionary algorithms”) \\nOR (“evolutionary programing”) \\nOR (“fuzzy systems”) OR (“fuzzy \\nlogic”) OR (“fuzzy set”) OR (“neuro-\\nfuzzy”) OR  (“bayesian inference”) \\nOR (“statistical inference”) OR \\n(“graphical model”) OR (“markov \\nmodel”) OR (“bayesian network”) \\nOR (“gaussian process”) OR  \\n(“logic programing”) OR (“inductive \\nprogramming”) OR (“deep learning”)} \\nAND { (“artificial intelligence”) OR \\n(“machine learning”)}Number of publications \\nof AI by countriesScimago SJR Scimago Lab\\nScopus  [26]\\nPatents in AI DOCDB database from the EPO \\n(European Patent Office) 102 \\nCountriesPatent inspiration [27] ANY in (“artificial intelligence”) OR \\n(“machine learning”) OR (“deep \\nlearning”)\\nTable 1.\\nSources of information used for Figures 2 and 3.\\n11 // Artificial Intelligence and Robotics'),\n",
       " Document(metadata={'source': 'data/AI_Robotics.pdf', 'page': 18}, page_content='2010 2011 2012 2013 2014 20152000\\n1750\\n1500\\n1250\\n1000\\n750500\\n250\\n0Venture Capital Investment in AI Technology\\n$ in Millions\\nSelf Driving\\nNatural Language ProcessingComputer Vision\\nImage RecognitionArtificial Intelligence Total\\nMachine Learning\\nFigure 4 \\nA conservative estimate of venture capital investment in AI \\ntechnology worldwide according to data presented in [28]. \\nArtificial Intelligence and Robotics  // 12\\n5. FINANCIAL IMPACT OF AI\\nIt has been well recognised that AI amplifies human \\npotential as well as productivity and this is reflected in \\nthe rapid increase of investment across many companies \\nand organisations. These include sectors in healthcare, \\nmanufacturing, transport, energy, banking, financial services, \\nmanagement consulting, government administration and \\nmarketing/advertising. The revenues of the AI market \\nworldwide, were around 260 billion US dollars in 2016 and \\nthis is estimated to exceed $3,060 billion by 2024 [23].  \\nThis has had a direct effect on robotic applications, including \\nexoskeletons, rehabilitation, surgical robots and personal \\ncare-bots. The economic impact of the next 10 years is \\nestimated to be between $1.49 and $2.95 trillion. These \\nestimates are based on benchmarks that take into account \\nsimilar technological achievements such as broadband, \\nmobile phones and industrial robots [28]. The investment \\nfrom the private sector and venture capital is a measure of \\nthe market potential of the underlying technology. In 2016, a \\nthird of the shares from software and information technology have been invested in AI, whereas in 2015, 1.16 billion US \\ndollars were invested in start-up companies worldwide, a \\n10-fold increase since 2009. \\nMajor technological firms are investing into applications \\nfor speech recognition, natural language processing and \\ncomputer vision. A significant leap in the performance of \\nmachine learning algorithms resulting from deep learning, \\nexploited the improved hardware and sensor technology \\nto train artificial networks with large amounts of information \\nderived from ‘big data’ [31, 32]. Current state-of-the-art AI \\nallows for the automation of various processes and new \\napplications are emerging with the potential to change the \\nentire workings of the business world. As a result, there is \\nhuge potential for economic growth, which is demonstrated \\nin the fact that between 2014 and 2015 alone, Google, \\nMicrosoft, Apple, Amazon, IBM, Yahoo, Facebook, and \\nTwitter, made at least 26 acquisitions of start-ups and \\ncompanies developing AI technology, totalling over $5 billion \\nin cost. '),\n",
       " Document(metadata={'source': 'data/AI_Robotics.pdf', 'page': 19}, page_content='2016 2017 2018 2019 2020 2021 2022 2023 2024 20251600000\\n1400000\\n1200000\\n1000000\\n800000\\n600000\\n400000\\n200000\\n0Predicted Economic Effect of A1\\n$ in Millions\\nCzernich et al. Qiang and Rossotto\\nFigure 5 \\nPredicted economic effect of AI worldwide estimated based \\non the GDP of mature economies and benchmark data from \\nbroadband Internet economic growth [29, 30].\\n13 // Artificial Intelligence and Robotics\\nIn 2014, Google acquired DeepMind, a London-based \\nstart-up company specialising in deep learning, for more \\nthan $500M and set a record of company investment of \\nAI research to academic standard. In fact, DeepMind has \\nproduced over 140 journal and conference papers and \\nhas had four articles published in Nature since 2012. One \\nof the achievements of DeepMind was in developing AI \\ntechnology able to create general-purpose software agents \\nthat adjust their actions based only on a cumulative reward. \\nThis reinforcement learning approach exceeds human level \\nperformance in many aspects and has been demonstrated \\nwith the defeat of the world Go game champion; marking a \\nhistorical landmark in AI progress. \\nIBM has developed a supercomputer platform, Watson, \\nwhich has the capability to perform text mining and extract \\ncomplex analytics from large volumes of unstructured \\ndata. To demonstrate its abilities, IBM Watson, in 2011, \\nbeat two top players on ‘Jeopardy!’, a popular quiz show, \\nthat requires participants to guess questions from specific answers. Although, information retrieval is trivial for computer \\nsystems, comprehension of natural language is still a \\nchallenge. This achievement has had a significant impact \\non the performance of web searches and the overall ability \\nof AI systems to interact with humans. In 2015, IBM bought \\nAlchemyAPI to incorporate its text and image analysis \\ncapabilities in the cognitive computing platform of the IBM \\nWatson. The system has already been used to process legal \\ndocuments and provide support to legal duties. Experts \\nbelieve that these capabilities can transform current health \\ncare systems and medical research.  \\nResearch in top AI firms is centred on the development \\nof systems that are able to reliably interact with people. \\nInteraction takes more natural forms through real-time \\nspeech recognition and translation capabilities. Robo-advisor \\napplications are at the top of the AI market with a globally \\nestimated 255 billion in US dollars by 2020 [23]. There are \\nalready several virtual assistants offered by major companies. \\nFor example, Apple offers Siri and Amazon Alexa, Microsoft '),\n",
       " Document(metadata={'source': 'data/AI_Robotics.pdf', 'page': 20}, page_content='Artificial Intelligence and Robotics  // 14\\noffers Cortana, and Google has the Google Assistant.  \\nIn 2016, Apple Inc. purchased Emotient Inc., a start-up \\nusing artificial-intelligence technology to read people’s \\nemotions by analyzing facial expressions. DeepMind created \\nWaveNet, which is a generative model that mimics human \\nvoices. According to the company’s website, this sounds \\nmore natural than the best existing Text-to-Speech systems. \\nFacebook is also considering machine-human interaction \\ncapabilities as a prerequisite to generalised AI. \\nRecently, OpenAI, a non-profit organisation, has been \\nfunded as part of a strategic plan to mitigate the risks of \\nmonopolising strong AI. OpenAI has re-designed evolutional \\nalgorithms that can work together with deep neural networks \\nto offer state-of-the-art performance. It is considered to \\nrival DeepMind since it offers similar open-source machine \\nlearning libraries to TensorFlow, a deep learning library \\ndistributed by Google DeepMind. Nevertheless, the big \\ndifference between the technology developed at OpenAI \\nand the other private tech companies, is that the created \\nIntellectual Property is accessible by everyone. Although several companies and organisations, including \\nDeepMind and OpenAI, envision the solution to the creation \\nof intelligence and the so-called Strong AI, developing \\nmachines with self-sustained long-term goals is well \\nbeyond current technology. Furthermore, there is vigorous \\ndebate on whether or not we are going through an AI \\nbubble, which encompasses the paradox that productivity \\ngrowth in USA, during the last decade, has declined \\nregardless of an explosion of technological progress and \\ninnovation. It is difficult to understand whether this reflects \\na statistical shortcoming or that current innovations are not \\ntransformative enough. This decline can be also attributed \\nto the lack of consistent policy frameworks and security \\nstandards that can enable the application of AI in projects  \\nof significant impact. '),\n",
       " Document(metadata={'source': 'data/AI_Robotics.pdf', 'page': 21}, page_content='Technology/Platforms AI Applications of significant impact Open-Source                                  Start-up acquisition\\nSearch engine, Maps, Ads, Gmail, \\nAndroid, Chrome, and YouTubeSelf-driving cars:  Technology that allows a \\ncar to navigate in normal traffic without any \\nhuman control.TensorFlow:  Construction of Deep Neural \\nNetworks\\nDeep Q-network: Deep Neural \\nNetworks with Reinforcement \\nLearning at scale.AlphaGo:  The first computer program to \\nbeat professional players of Go. \\nDQN:  Better than human-level control of \\nAtari games through Deep Reinforcement \\nLearning.\\nWavenet:  Raw audio form impersonating any \\nhuman voice DeepMind Lab:  3D game-like platform for \\nagent-based AI research\\nSonnet:  Constructing Deep Neural \\nNetworks based on TensorFlow\\nNon-profit organisation\\nEvolutionary Algorithms \\nDeep Neural Networks Evolutionary Algorithms  tuned to work with \\nDeep Neural Networks\\nTestbeds for AI:  Benchmarking tools and \\nperformance measures for AI algorithms.Gym:  Toolkit for developing and comparing \\nreinforcement learning algorithms.\\nUniverse:  Measure an AI’s general \\nIntelligence\\nManufacturer of computer \\nhardware and software\\nHosting and consulting services\\nCognitive ComputingDeep Blue:  First computer program to defit \\nworld champion chess player\\nWatson: Won top players on ‘Jeopardy!’, a \\npopular quiz show. Apache SystemML:  Distribution of large-\\nscale machine learning computations on \\nApache Hadoop and Spark.\\nApache UIMA:  Unstructured Information \\nManagement\\nSocial Networking Service Applied Machine Learning: Spot suicidal \\nusers\\nHuman Computer Interaction:  Image \\nDescriptions for Blind UsersCommAI-env:  A Communication-based  \\nplatform for training and evaluating AI \\nsystems.\\nfbcunn:  Deep learning modules for GPUs\\nComputer hardware and software\\nConsumer electronics\\nOnline servicesSiri: AI Virtual Assistant\\nSelf-driving car:  AI technology that could \\ndrive a car without human interaction.\\nCloud Computing\\nOnline retail services\\nElectronicsAlexa:  AI virtual assistant\\nAmazon AI platform:  Cloud software and \\nhardware AI toolsDSSTNE:  Deep Scalable Sparse Tensor \\nNetwork Engine\\nDeveloping, manufacturing and \\nlicensing computer hardware and \\nsoftware\\nConsumer electronicsMicrosoft Azure:  Cloud services\\nCortana:  AI virtual assistantCNTK:  Cognitive Toolkit\\nMicrosoft Azure:  Cloud computing \\nplatform offered as a service. \\nTable 2.\\nMajor companies in AI\\n15 // Artificial Intelligence and Robotics'),\n",
       " Document(metadata={'source': 'data/AI_Robotics.pdf', 'page': 22}, page_content='Technology/Platforms AI Applications of significant impact Open-Source                                  Start-up acquisition\\nSearch engine, Maps, Ads, Gmail, \\nAndroid, Chrome, and YouTubeSelf-driving cars:  Technology that allows a \\ncar to navigate in normal traffic without any \\nhuman control.TensorFlow:  Construction of Deep Neural \\nNetworks\\nDeep Q-network: Deep Neural \\nNetworks with Reinforcement \\nLearning at scale.AlphaGo:  The first computer program to \\nbeat professional players of Go. \\nDQN:  Better than human-level control of \\nAtari games through Deep Reinforcement \\nLearning.\\nWavenet:  Raw audio form impersonating any \\nhuman voice DeepMind Lab:  3D game-like platform for \\nagent-based AI research\\nSonnet:  Constructing Deep Neural \\nNetworks based on TensorFlow\\nNon-profit organisation\\nEvolutionary Algorithms \\nDeep Neural Networks Evolutionary Algorithms  tuned to work with \\nDeep Neural Networks\\nTestbeds for AI:  Benchmarking tools and \\nperformance measures for AI algorithms.Gym:  Toolkit for developing and comparing \\nreinforcement learning algorithms.\\nUniverse:  Measure an AI’s general \\nIntelligence\\nManufacturer of computer \\nhardware and software\\nHosting and consulting services\\nCognitive ComputingDeep Blue:  First computer program to defit \\nworld champion chess player\\nWatson: Won top players on ‘Jeopardy!’, a \\npopular quiz show. Apache SystemML:  Distribution of large-\\nscale machine learning computations on \\nApache Hadoop and Spark.\\nApache UIMA:  Unstructured Information \\nManagement\\nSocial Networking Service Applied Machine Learning: Spot suicidal \\nusers\\nHuman Computer Interaction:  Image \\nDescriptions for Blind UsersCommAI-env:  A Communication-based  \\nplatform for training and evaluating AI \\nsystems.\\nfbcunn:  Deep learning modules for GPUs\\nComputer hardware and software\\nConsumer electronics\\nOnline servicesSiri: AI Virtual Assistant\\nSelf-driving car:  AI technology that could \\ndrive a car without human interaction.\\nCloud Computing\\nOnline retail services\\nElectronicsAlexa:  AI virtual assistant\\nAmazon AI platform:  Cloud software and \\nhardware AI toolsDSSTNE:  Deep Scalable Sparse Tensor \\nNetwork Engine\\nDeveloping, manufacturing and \\nlicensing computer hardware and \\nsoftware\\nConsumer electronicsMicrosoft Azure:  Cloud services\\nCortana:  AI virtual assistantCNTK:  Cognitive Toolkit\\nMicrosoft Azure:  Cloud computing \\nplatform offered as a service. 2012\\n2012\\n2012\\n2012\\n2012\\n20122017\\n2017\\n2017\\n2017\\n2017\\n2017\\nNatural language \\nprocessing Machine\\nvisionRobotics Machine\\nlearningOthers\\nArtificial Intelligence and Robotics  // 16'),\n",
       " Document(metadata={'source': 'data/AI_Robotics.pdf', 'page': 23}, page_content='17 // Artificial Intelligence and Robotics\\nFor the first time, the UK government has singled \\nout robotics and AI in its blueprint for a ‘modern’ \\nindustrial strategy. It brings some certainty in \\nthis uncertain time, demonstrating the UK’s drive \\nto kick-start disruptive technologies that could \\ntransform our economy, with a clear vision for \\npositioning the UK in the international landscape.'),\n",
       " Document(metadata={'source': 'data/AI_Robotics.pdf', 'page': 24}, page_content='Artificial Intelligence and Robotics  // 18\\nAI is a diverse field of research and the following subfields \\nare essential to its development. These include neural \\nnetworks, fuzzy logic, evolutionary computation, and \\nprobabilistic methods.\\nNeural networks  build on the area of connectionism with \\nthe main purpose of mimicking the way the nervous system \\nprocesses information. Artificial Neural Networks (ANN) and \\nvariants have allowed significant progress of AI to perform \\ntasks relative to “perception”. When combined with the \\ncurrent multicore parallel computing hardware platforms, \\nmany neural layers can be stacked to provide a higher level \\nof perceptual abstraction in learning its own set of features, \\nthus removing the need for handcrafted features; a process \\nknown as deep learning [33]. Limitations of using deep \\nlayered ANN include 1) low interpretability of the resultant \\nlearned model, 2) large volumes of training data and \\nconsiderable computational power are often required for the \\neffective application of these neural models.\\nDeep learning  is part of machine learning and is usually \\nlinked to deep neural networks that consist of a multi-\\nlevel learning of detail or representations of data. Through \\nthese different layers, information passes from low-level \\nparameters to higher-level parameters. These different \\nlevels correspond to different levels of data abstraction, \\nleading to learning and recognition. A number of deep \\nlearning architectures, such as deep neural networks, deep \\nconvolutional neural networks and deep belief networks, \\nhave been applied to fields such as computer vision, \\nautomatic speech recognition, and audio and music signal \\nrecognition and these have been shown to produce cutting-\\nedge results in various tasks.\\nFuzzy logic  focuses on the manipulation of information \\nthat is often imprecise. Most computational intelligence \\nprinciples account for the fact that, whilst observations \\nare always exact, our knowledge of the context, can often \\nbe incomplete or inaccurate as it is in many real-world \\nsituations. Fuzzy logic provides a framework in which to \\noperate with data assuming a level of imprecision over a  \\nset of observations, as well as structural elements to \\nenhance the interpretability of a learned model [34]. It does \\nprovide a framework for formalizing AI methods, as well as \\nan accessible translation of AI models into electronic circuits. \\nNevertheless, fuzzy logic does not provide learning abilities \\nper se, so it is often combined with other aspects such a \\nneural networks, evolutionary computing or  \\nstatistical learning.Evolutionary computing  relies on the principle of natural \\nselection, or natural patterns of collective behaviour [35]. \\nThe two most relevant subfields include genetic algorithms \\nand swarm intelligence. Its main impact on AI is on multi-\\nobjective optimization, in which it can produce very robust \\nresults. The limitations of these models are like neural \\nnetworks about interpretability and computing power.\\nStatistical Learning  is aimed at AI employing a more \\nclassically statistical perspective, e.g., Bayesian modelling, \\nadding the notion of prior knowledge to AI. These methods \\nbenefit from a wide set of well-proven techniques and \\noperations inherited from the field of classical statistics, as \\nwell as a framework to create formal methods for AI. The \\nmain drawback is that, probabilistic approaches express \\ntheir inference as a correspondence to a population [36]  \\nand the probability concept may not be always applicable, \\nfor instance, when vagueness or subjectivity need to be \\nmeasured and addressed [37].\\nEnsemble learning and meta-algorithms  is an area of AI \\nthat aims to create models that combine several weak base \\nlearners in order to increase accuracy, while reducing its bias \\nand variance. For instance, ensembles can show a higher \\nflexibility with respect to single model approaches on which \\nsome complex patterns can be modelled. Some well-known \\nmeta-algorithms for building ensembles are bagging and \\nboosting. Ensembles can take advantage of significant \\ncomputational resources to train many base classifiers \\ntherefore enhancing the ability to augment resolution of the \\npattern search - although this does not always assure the \\nattainment of a higher accuracy. \\nLogic-based artificial intelligence  is an area of AI commonly \\nused for task knowledge representation and inference. It can \\nrepresent predicate descriptions, facts and semantics of a \\ndomain by means of formal logic, in structures known as \\nlogic programs. By means of inductive logic programming \\nhypotheses can be derived over the known background. 6.  SUBFIELDS AND TECHNOLOGIES THAT \\nUNDERPINNINGS ARTIFICIAL INTELLIGENCE'),\n",
       " Document(metadata={'source': 'data/AI_Robotics.pdf', 'page': 25}, page_content='1940 1945 1950 1955 1960 1965 1970 1975 1980 1985 1990 1995 2000 2005 2010 2015First AI stage: The beginning Second AI stage: Network Design Third AI stage: Hardware Acceleration\\n1943:\\nThreshold Logic Unit\\n1958:Perceptron\\n1974:Backpropagation \\n1985:  Boltzmann Machine\\n1987: Convolutional neural nets\\n1993: Reinforcement Learning\\n1997: Long Short Term Memory\\n2009: Large scale learning using GPU\\n2014: Real-time translation\\n 2017: DeepStack\\n1950:Turing test\\n 1969:XOR affair\\n1986:Autoenconders\\n 2006: Deep belief nets\\n2012: ImageNet classification\\n1992: Belief nets\\n1989: Recurrent neural nets\\n 1995: Learning to play chess\\n2016: AlphaGo\\nFigure 6\\nTimeline of the main discoveries and seasons in AI: from perceptron to deep learning\\n19 // Artificial Intelligence and Robotics\\nThe idea of creating an artificial machine is as old as the \\ninvention of the computer. Alan Turing in the early 1950s \\nproposed the Turing test, designed to assess whether a \\nmachine could be defined as intelligent. Two of the main \\npioneers in this field are Pitts and McCulloch [38] who, in \\n1943, developed a technique designed to mimic the way \\na neuron works. Inspired by this work, a few years later, \\nFrank Rosenblatt [39] developed the first real precursor \\nof the modern neural network, called Perceptron. This \\nalgorithm describes an automatic learning procedure that \\ncan discriminate linearly separable data. Rosenblatt was \\nconfident that the perceptron would lead to an AI system in \\nthe future. The introduction of perceptron, in 1958, signalled \\nthe beginning of the AI evolution. For almost 10 years \\nafterwards, researchers used this approach to automatically \\nlearn how to discriminate data in many applications, until \\nPapert and Minsky [3], demonstrated a few important \\nlimitations of Perceptron. This slowed down the fervour \\nof AI progress and more specifically, they proved that the \\nperceptron was not capable of learning simple functions, \\nsuch as the exclusive-or XOR, no matter how long the \\nnetwork was trained.Today, we know that the model implied by the perceptron is \\nlinear and the XOR function does not belong to this family, \\nbut at the time this was enough to stop the research behind \\nneural nets and began the first AI winter. Much later in 1974, \\nthe idea of organizing the perceptron in layers and training \\nthem using the delta rule [40] shaped the creation of more \\ncomplex neural nets. With the introduction of the Multilayer \\nNeural Nets [41], researchers were confident that adding \\nmultiple hidden layers to the networks would produce deep \\narchitectures that further increase the complexity of the \\nhypothesis that can be expressed. However, the hardware \\nconstraints that were present at that time, limited, for many \\nyears, the number of layers that could be used in practice. \\nTo overcome these hardware limitations different network \\nconfigurations were proposed. For almost another decade, \\nresearchers focused on producing new efficient network \\narchitectures that are suitable for specific contexts. Notably, \\nthese developments included the Autoencoder [42] useful in \\nextracting relevant features from data, the Belief nets used to \\nmodel statistical variables, the Recurrent neural nets [43] and \\nits variant Long Short Term Memory [44] used for processing \\nsequence of data, and the Convolutional neural nets [45] \\nused to process images. Despite these new AI solutions, the \\naforementioned hardware limitations were a big restriction \\nduring training. 7.  THE RISE OF DEEP LEARNING: RETHINKING THE \\nMACHINE LEARNING PIPELINE'),\n",
       " Document(metadata={'source': 'data/AI_Robotics.pdf', 'page': 26}, page_content='1940 1945 1950 1955 1960 1965 1970 1975 1980 1985 1990 1995 2000 2005 2010 2015First AI stage: The beginning Second AI stage: Network Design Third AI stage: Hardware Acceleration\\n1943:\\nThreshold Logic Unit\\n1958:\\nPerceptron\\n 1974:\\nBackpropagation \\n1985:  \\nBoltzmann Machine\\n1987: Convolutional neural nets\\n1993: Reinforcement Learning\\n1997: Long Short Term Memory\\n2009: Large scale learning using GPU\\n2014: Real-time translation\\n 2017: DeepStack\\n1950:Turing test\\n 1969:XOR affair\\n1986:Autoenconders\\n 2006: Deep belief nets\\n2012: ImageNet classification\\n1992: Belief nets\\n1989: Recurrent neural nets\\n 1995: Learning to play chess\\n2016: AlphaGo\\nArtificial Intelligence and Robotics  // 20\\nWith recent hardware advances, such as the parallelization \\nusing GPU, the cloud computing and the multi-core \\nprocessing finally led to the present stage of AI. In this \\nstage, deep neural nets have made tremendous progress \\nin terms of accuracy and they can now recognize complex \\nimages and perform voice translation in real time. However, \\nresearchers are still dealing with issues relating to the \\noverfitting of the networks, since large datasets are often \\nrequired and not always available. Furthermore, with the \\nvanishing of the gradient, this leads to a widespread problem \\ngenerated during the training of a network with many layers. \\nFor this reason, more sophisticated training procedures \\nhave recently been proposed. For example, in 2006, Hinton \\nintroduced the idea of unsupervised pretraining and Deep \\nBelief Nets [46]. This approach has each pair of consecutive \\nlayers trained separately using an unsupervised model \\nsimilar to the one used in the Restricted Boltzman Machine \\n[47]; then the obtained parameters are frozen and a new \\npair of layers are trained and stacked on top of the previous \\nones. This procedure can be repeated many times leading \\nto the development of a deeper architecture with respect \\nto the traditional neural nets. Moreover, this unsupervised \\npre-training approach has led to increasing neural net papers \\nwhen in 2014, for the first time, a neural model became \\nstate-of-the-art in the speech recognition. In 2010, a large database, known as Imagenet containing \\nmillions of labelled images was created and this was \\ncoupled with an annual challenge called Large Scale Visual \\nRecognition Challenge. This competition requires teams of \\nresearchers to build AI systems and they receive a score \\nbased on how accurate their model is. In the first two years \\nof the contest, the top models had an error rate of 28% \\nand 26%. In 2012, Krizhevsky, Sutskever and Hinton [48] \\nsubmitted a solution that had an error rate of just 16% and \\nin 2015 the latest submitted models [49] were capable of \\nbeating the human experts with an overall error of 5%. One \\nof the main components of this significant improvement, in \\nsuch a short time, was due to the extensive use of graphics \\nprocessing units (GPUs) for speeding up the training \\nprocedure, thus allowing the use of larger models which also \\nmeant a lower error rate in classification.\\nIn the last 3 years researchers have also been working on \\ntraining deep neural nets that are capable of beating human \\nexperts in different fields, similar to the solution used for \\nAlphaGo [50] or DeepStack [51]and in 2017, they overtook \\nhuman experts with 44000 played hands of poker.'),\n",
       " Document(metadata={'source': 'data/AI_Robotics.pdf', 'page': 27}, page_content='21 // Artificial Intelligence and Robotics\\n1985:  \\nBoltzmann MachinesBoltzmann Machines represent a type of neural network modelled by using stochastic \\nunits with a specific distribution (for example Gaussian). Learning procedure involves \\nseveral steps called Gibbs sampling, which gradually adjust the weights to minimize \\nthe reconstruction error. They are useful if it is required to model probabilistic \\nrelationships between variables. A variant of this machine is the Restricted Boltzmann \\nMachines where the visible and hidden units are restricted to form a bipartite graph \\nthat allows implementation of more efficient training algorithms. \\n1986:  \\nAutoEncoderAn Autoencoder is a neural network designed to extract features directly from the \\ndata. This network has the same number of input and output nodes and it is trained \\nusing an unsupervised approach to recreate the input vector rather than to assign a \\nclass label to it. Usually, the number of hidden units is smaller than the input/output \\nlayers, which achieve encoding of the data in a lower dimensional space and extract \\nthe most discriminative features.\\n1987:  \\nConvolutional neural network (CNN)CNNs have been proposed to process efficiently imagery data. The name of these \\nnetworks comes from the convolution operator that provides an easy way to perform \\ncomplex operations using convolution filter. CNNs use locally connected neurons \\nthat represent data specific kernels. The main advantage of a CNN is that during \\nback-propagation, the network has to adjust a number of parameters equal to a \\nsingle instance of the kernel which drastically reduces the connections from the \\ntypical neural network. The concept of CNN is inspired by the neurobiological model \\nof the visual cortex and can be briefly summarized as a sequence of convolution and \\nsubsampling of the image until high level features can be extracted.\\n1989:  \\nRecurrent neural nets (RNN)RNN is a neural network that contains hidden units capable of analysing streams \\nof data. Since RNN suffers from the vanishing gradient and exploding gradient \\nproblems, a variation called Long Short-Term Memory units (LSTMs) was proposed in \\n1997 to solve this problem. Specifically, LSTM is particularly suitable for applications \\nwhere there are very long time lags of unknown sizes between important events. \\nRNN and LSTM share the same weights across all steps that greatly reduce the total \\nnumber of parameters that the network needs to learn. RNNs have shown great \\nsuccesses in many Natural Language Processing tasks such as language modelling, \\nbioinformatics, speech recognition and generating image description.HIDDEN LA YER\\nOUTPUT LA YER INPUT LA YERHIDDEN LA YER\\nOUTPUT\\nSTREAM\\nMEMORY\\nINPUT\\nSTREAMOt-2Ot-1OtOt+1\\nSt-2St-1StSt+1\\nYt-2Yt-1Yt1Yt+1'),\n",
       " Document(metadata={'source': 'data/AI_Robotics.pdf', 'page': 28}, page_content=\"1\\n1975 1980 1985 1990 1995 2000 2010 2015101001000     10000100000100000010000000Transistors (Thousands)\\nFrequency (MHz)\\n2005Typical Power (W atts)\\nNumber of Cor esHistory of general-purpose CPUs: \\nEvolution of the main characteristics\\nIntel®\\n8080Motor ola \\n680000Mips\\n r2000Am386 Intel® \\nPentium Pr oIntel® \\nPentium IIIIntel® \\nPentium MIntel® \\nCore i7Intel® Xeon \\nPhi™\\nIntel®\\n otorola\\n ®\\n Mo\\n ps\\nMip\\n Am386\\n Intel® \\n Intel® \\n Intel® \\n Intel® \\n Intel® Xeon\\nFigure 7\\nHistory of general-purpose CPUs: Evolution of the main characteristics\\nArtificial Intelligence and Robotics  // 22\\nIn 1965, Gordon Moore observed that the number \\nof transistors, in a dense integrated circuit, doubles \\napproximately every year. Ten years later, he revised his \\nforecast, updating his prediction to the number doubling \\nevery two years. Moore's prediction has been accurate for \\nseveral decades and has been used in the semiconductor \\nindustry to guide long-term planning. In 2015, Moore \\nrealised that the rate of progress in the hardware would \\nreach saturation and the transistors would arrive at the limits \\nof miniaturisation at the atomic level. Experts estimate that \\nMoore’s law could end in 2025. Today, his prediction is  \\nstill valid and the number of transistors is increasing  even if, after 2005, the frequency and the power started to \\nreduce, leading to a core scaling rather than a frequency \\nimprovement. Therefore, since 2005, we are no longer \\ngetting faster computers, but the hardware is designed in \\na multi-core manner. To take full advantage of this different \\nhardware implementation, the software has to be written \\nin a multi-threaded manner too. In future, experts believe \\nthat revolutionary technologies may help sustain Moore's \\nlaw. One of the key challenges will be the design of gates in \\nnanoscale transistors and the ability of controlling the current \\nflow as, when the device dimension shrinks, the connection \\nbetween transistors becomes more difficult. 8. HARDWARE FOR AI\"),\n",
       " Document(metadata={'source': 'data/AI_Robotics.pdf', 'page': 29}, page_content=\"1960 Central Pr ocessing Unit (CPU):  \\nIntegrated cir cuits that allow large \\nnumber of transistors to be \\nmanufactur ed in a single chip. 2001 Graphics Processing Unit (GPU): \\nNvidia intr oduced the term \\nGPU for integrated chips with image formation/ rendering engines. 2010 Junction less transistor: A contr ol gate wrapped ar ound \\na silicon nanowir e that can \\ncontr ol the passage of \\nelectr ons without the use of \\njunctions or doping.2014 T rueNorth –Neur omorhpic \\nAdaptive Plastic Scalable Electr onics:\\n \\nThe first neur omorphic integrated cir cuit \\nto achieve one million individually programmable neur ons with 256 \\nindividually pr ogrammable synapses.\\n1990: Field Pr ogrammable \\nGate Array (FPGA): Integrated cir cuits designed to \\nbe configur ed after \\nmanufacturing.2008 Memristor: A fourth basic passive cir cuit \\nelement. The memristor's properties permit the cr eation \\nof smaller and better -perform-\\ning electr onic devices.2011 single-electr on \\ntransistor: 1.5 nanometr es \\nin diameter , made out of \\noxide based materials. Could spur the cr eation of \\nmicroscopic computers.2015 3D Xpoint: \\nNon-volatile memory \\nclaimed to be significantly faster . \\n \\nFigure 8\\nTimeline of the main hardware discoveries that have influenced the evolution of an AI system\\n23 // Artificial Intelligence and Robotics\\nModern machines combine powerful multicore CPUs with \\ndedicated hardware designed to solve parallel processing.  \\nGPU and FPGA are the most popular dedicated hardware \\ncommonly available in workstations  developing AI systems. \\nA GPU (Graphics Processing Unit) is a chip designed to \\naccelerate the processing of multidimensional data such as an \\nimage. A GPU consists of thousands of smaller cores, intended \\nto work independently on a subspace of the input data, that \\nneeds heavy computation. Repetitive functions that can be \\napplied to different parts of the input, such as texture mapping, \\nimage rotation, translation and filtering, are performed at a much \\nfaster rate and more efficiently, through the use of the GPU.  \\nA GPU has dedicated memory and the data must be moved in \\nand out in order to be processed.FPGA (Field Programmable Gate Array) is a reconfigurable \\ndigital logic containing an array of programmable logic blocks \\nand a hierarchy of reconfigurable interconnections. An FPGA \\nis not a processor and therefore it cannot run a program \\nstored in the memory. An FPGA is configured using a hardware \\ndescription language (HDL) and unlike the traditional CPU, it is \\ntruly parallel. This means, that each independent processing \\ntask is assigned to a dedicated section of the chip and many \\nparts of the same program can be performed in simultaneously. \\nA typical FPGA may also have dedicated memory blocks, digital \\nclock manager, IO banks and several other features, which vary \\nacross different models. While a GPU is designed to perform \\nefficiently, with similar threads on different subsets of the input, \\nan FPGA is designed to parallelize sequential serial processing \\nof the same program.\"),\n",
       " Document(metadata={'source': 'data/AI_Robotics.pdf', 'page': 30}, page_content='Artificial Intelligence and Robotics  // 24\\n9. ROBOTICS AND AI\\nBuilding on the advances made in mechatronics, electrical \\nengineering and computing, robotics is developing \\nincreasingly sophisticated sensorimotor functions that \\ngive machines the ability to adapt to their ever-changing \\nenvironment. Until now, the system of industrial production \\nwas organized around the machine; it is calibrated according \\nto its environment and tolerated minimal variations. \\nToday, it can be integrated more easily into an existing \\nenvironment. The autonomy of a robot in an environment \\ncan be subdivided into perceiving, planning and execution \\n(manipulating, navigating, collaborating). The main idea of \\nconverging AI and Robotics is to try to optimise its level of \\nautonomy through learning. This level of intelligence can be \\nmeasured as the capacity of predicting the future, either in \\nplanning a task, or in interacting (either by manipulating or \\nnavigating) with the world. Robots with intelligence have \\nbeen attempted many times. Although creating a system \\nexhibiting human-like intelligence remains elusive, robots that \\ncan perform specialized autonomous tasks, such as driving \\na vehicle [52], flying in natural and man-made environments \\n[53], swimming [54], carrying boxes and material in different \\nterrains [55], pick up objects [56] and put them down [57]  \\ndo exist today. \\nAnother important application of AI in robotics is for the task \\nof perception. Robots can sense the environment by means \\nof integrated sensors or computer vision. In the last decade, \\ncomputer systems have improved the quality of both sensing and vision. Perception is not only important for planning but \\nalso for creating an artificial sense of self-awareness in the \\nrobot. This permits supporting interactions with the robot \\nwith other entities in the same environment. This discipline \\nis known as social robotics. It covers two broad domains: \\nhuman-robot interactions (HCI) and cognitive robotics. \\nThe vision of HCI it to improve the robotic perception of \\nhumans such as in understanding activities [58], emotions \\n[59], non-verbal communications [60] and in being able to \\nnavigate an environment along with humans [61]. The field \\nof cognitive robotics focuses on providing robots with the \\nautonomous capacity of learning and acquiring knowledge \\nfrom sophisticated levels of perception based on imitation \\nand experience. It aims at mimicking the human cognitive \\nsystem, which regulates the process of acquiring knowledge \\nand understanding, through experience and sensorisation \\n[62]. In cognitive robotics, there are also models that \\nincorporate motivation and curiosity to improve the quality \\nand speed of knowledge acquisition through learning  \\n[63, 64]. \\nAI has continued beating all records and overcoming many \\nchallenges that were unthinkable less than a decade ago. \\nThe combination of these advances will continue to reshape \\nour understanding about robotic intelligence in many new \\ndomains. Figure 9 provides a timeline of the milestone in \\nrobotics and AI.'),\n",
       " Document(metadata={'source': 'data/AI_Robotics.pdf', 'page': 31}, page_content=\"25 // Artificial Intelligence and Robotics\\n2016 Nanorobots:  A team from Polytechnique of \\nMontréal created a nanotransporter-bot that can \\nadminister drugs without damaging surrounding \\norgans and tissues.\\n2014 Robot exoskeleton:   A complete paralysed \\nman was able to walk again using a robotic \\nexoskeleton designed by Ekso Bionics. \\n2014 Pepper:  Japanese company Softbank \\npresented the first robot, so-named Pepper, to be \\nused for customer service. The robot has integrated \\nan emotion engine to interact with people.\\n2010 3D Printing:  First 3D printers were made \\ncommercially available.\\n2010 IBM Watson:  IBM's Watson computer beat \\nhuman champions on the game show Jeopardy!\\n by analysing natural language and finding answers \\nto questions more rapidly and accurately than its \\nhuman rivals.\\n2005 Robot BigDog:  Boston Dynamics created \\nthe first robot that could carry 150 Kg of \\nequipment. The robot was able to traverse rough \\nterrains using its four legs.\\n2004 Mars Robot:  Robots landed on mars. \\nAlthough they were only supposed to work for 90 \\ndays, they extended their lifetime for several years \\nand remain operative until today.\\n2000 DaVinci Surgical System:  A surgical \\nrobot for minimally invasive (keyhole) surgery was \\napproved by the FDA. The robot is controlled by a \\nsurgeon from a master console.\\n1999 Aibo Robot:  First robotic pet dog. It \\ncould “learn”, interact with its enviornment and \\nresponded more than 100 voice commands.\\n1997 First Robocup competition:  An international \\ncompetition for promoting AI and robotics where \\nrobots play a soccer tournament and other \\ndexterity games.\\n1989 MQ-1 Predator drone:  The predator drone \\nis introduced by the United State Air Force. It was \\nequipped with reconnaissance cameras and could \\ncarry missiles.\\n1987 Mitsubishi Movemaster:  It was the first \\nsmall robotic arm gripper which could perform \\ntasks such as assembling small products or \\nhandling chemicals\\n2017 Go is solved:  A team from Google DeepMind \\ncreated an algorithm named AlphaGo that beat top \\nplayers of the ancient far-eastern board game Go.\\n2016 Microfluidic robot:  The first autonomous, \\nentirely soft robot powered by a chemical reaction \\nand a microfluidic logic was developed by a team \\nat Harvard University.\\n2010 iCub:  A 1 meter high humanoid robot for \\nresearch in human cognition at IIT, Italy. The robot \\ncan express emotions and is equipped with tactile \\nsensors to interact with the environment.\\n2010 Robotnaut 2:  NASA revealed a  humanoid \\nrobot with a wide range of sensors that can replace \\nhuman astronauts.\\n2007 Checkers is solved:  A program from \\nUniversity of Alberta named Chinook was able to \\nsolve the problem of checkers and beat humans at \\nseveral competitions.\\n2005 Autonomous vehicle challenge:  A team \\nfrom Stanford University won the challenge \\norganized by DARPA for driving autonomously off-\\nroad across a 175-mile long desert terrain without \\nhuman intervention.\\n2002 Darpa’s Centibots:  First collaborative robot \\nswarm of mobile robots that could survey an \\narea and build a map in real time without human \\nsupervision.\\n2002 Roomba:  The first household robot for \\ncleaning. It was able to detect and avoid obstacles \\nas well as navigating within a house without using \\nmaps.\\n2000 Asimo:  Robot Asimo from Honda presented \\nthe first humanoid robot that could walk like \\nhumans, climb stairs, change its direction and \\ndetect hazards using a video camera.\\n1997 Deep blue beats Garry Kasparov:  After \\na rematch in 2016, deep blue defeated Garry \\nKasparov by 2 to 1. \\n1992 End of next AI project:  End of Japan’s \\nmultimillion program for developing the fifth \\ngeneration computer systems based on AI.\\n1989 Computer beats Human at chess:  \\nComputers beat humans at chess for the first time.\"),\n",
       " Document(metadata={'source': 'data/AI_Robotics.pdf', 'page': 32}, page_content=\"Figure 9\\nA timeline of robotics and AI. \\nArtificial Intelligence and Robotics  // 26\\n1985 Denning Sentry Robot:  The first security \\nsentry robot was developed, which could patrol for \\nmore than 14 hours and alert about anything unusual \\nin a range of 150-foot radius. \\n1982 FRED robot:  The first playful robot was \\ndeveloped by Atari engineering. It never made it to \\nthe market.\\n1979 Stanford Cart:  A most advanced mobile robot \\nthat was able to move through a room avoiding \\nobstacles. It was able to take pictures about the \\nenvironment from different angles.\\n1974 The silver arm:  MIT designed the first robot \\nthat is able to assemble small parts. The robot was \\nequipped with pressure and touch sensors to mimic \\nthe soft touch of human fingers.\\n1970 The Tentacle Arm:  Marvin Minsky designed \\na tentacle arm robot inspired by an octopus. It had \\nmore than twelve tentacles that allowed the robot to \\ngo around obstacles.\\n1963 The Rancho Arm:  The first assistive robot \\nwas developed at a hospital in California and later \\ncontrolled by a computer at Stanford University. The \\nrobot was composed of six joints used as  a tool \\nfor the handicapped. This is the first robotic arm \\ncontrolled by a computer. \\n1959 Automatically Programmed Tools:  The first \\ncomputer assisted manufacturing (CAM) system \\ndeveloped at MIT.\\n1951 Robot Squee:  A robot inspired by a squirrel \\nwith the capacity of sensing the environment using \\nlight sensors.\\n1950 Robot Elsie:  Grey Walter developed the \\nfirst mobile robot (automaton) with a goal-seeking \\nbehaviour.\\n1941:  Isaac Asimov's article published in Astounding \\nScience Fiction: For the first time the term “robot” \\nwas used in an article and the three laws of robotics \\nwere presented.\\n1984 Hero Robot Kit:  First playful robot with \\nhuman interaction abilities. It could navigate a room \\nguided by sonar and tried to remain near humans by \\nlistening to their voices.\\n1981 Direct Drive arm:  The technology of the direct \\ndrive arm was first presented by Takeo Kanade. This \\nhelped minimise a lot of the friction and backlash of \\nearlier robots that used chains and tendons.\\n1978 Speak and Spell:  The first commercially \\navailable human artificial speech system, by Texas \\nInstruments Inc. The system was able to perform a \\nmathematical model of the human track and elicit \\nhuman sounds.\\n1970 Shakey the robot:  The first mobile robot able \\nto navigate within an environment using AI. It was \\nequipped with a TV camera, laser range finders and \\nbump sensors. It could also communicate wirelessly \\nover a radio link.\\n1969 Stanford Robotic arm:  The first electrically \\npowered computer-controlled robot arm. The robot \\nused a set of optical and contact sensors.\\n1963 The Orm robot:  A team at Stanford university \\ndeveloped the first soft-robot inspired by snake. \\n1961 Unimate:  The first robot for industrial mass-\\nproduction started working at General Motors. \\n1956 Alan Turing’s Test:  Alan Turing proposed a \\ntest to be able to identify whether the machine is \\ningelligent.\\n1950 Isaac Assimov published I, Robot:  The first \\nnovel literature book dedicated to Robots.\\n1948 Norbert Wiener Cybernetics:   The term \\nCybernetics was coined for the first time and a \\npotential convergence of artificial intelligence (first \\nproposed by Walter Pitts as logical calculus) and \\ncontrol systems.\\n1939 Elektro and Sparko:  The first robot \\n(automaton) was presented at the world’s fair.\"),\n",
       " Document(metadata={'source': 'data/AI_Robotics.pdf', 'page': 33}, page_content='Logo Language Date Type Infuenced by AI resources\\nLisp 1958 Multi-paradigm \\n(functional, \\nprocedural) IPL •  Homoiconic: easy to deal with large amount of data.\\n•  Good mathematical alignment.\\n•  Lots of resources for symbolic AI (Eurisko or CYC)\\nC++ 1983 Procedural C, Algol 68 • Fast execution times.\\n•  Some compatible libraries for AI such as Alchemy  \\nfor Markov logic and Mlpack for general ML\\nC# 2000 Multi-paradigm \\n(functional, \\nprocedural) C++, Java, \\nHaskell•  Easy prototyping and well elaborated environment.\\n•  Most used language for AI in games as provides good \\ncompatibility with popular games engines such as \\nUnity.\\nClojure 2007 Functional Lisp, Erlang, \\nProlog•  Easy design and cloud infrastructure that works on \\ntop of the JVM.\\n•  Rapid interactive development and libraries for \\ndevelopment of behaviour trees (alter-ego)\\nErlang 1986 Functional\\nConcurrentLisp, Prolog •  Good framework to deal with concurrency and elastic \\nclouds (scalability).\\n•  Libraries for logic programming such as erlog.\\nGo 2009 Procedural\\nConcurrentAlgo, CSP , \\nPython•  Easy concurrency and asynchronous patterns with a \\ndecent runtime.\\n•  A few libraries for machine learning such as Golearn.\\nHaskell 1990 Functional Lisp •  Easy parallelization and possibility of handling infinite \\ncomputations. \\n•  A few utilities to implement neural networks \\n(LambdaNet) and general ML (HLearn).\\nJava 1995 Procedural\\nConcurrentC++, Ada 83 •  VM provides efficient maintainability, portability and \\ntransparency.\\n•  A myriad for libraries and tools for AI such as Tweety \\nand ML (DeepLearning4, Weka, Mallet etc.)\\nJulia 2012 Multi-paradigm Lisp, Lua, \\nMatlab, Python•  Easy integration with C and Fortran. Scientific oriented \\nlanguage.\\n•  Several ML packages such as Mocha, or MLBase.\\n27 // Artificial Intelligence and Robotics\\n10.  PROGRAMMING LANGUAGES FOR AI'),\n",
       " Document(metadata={'source': 'data/AI_Robotics.pdf', 'page': 34}, page_content='Logo Language Date Type Infuenced by AI resources\\nLua (procedural, \\nfunctional)C++, Scheme • Versatile and lightweight language.\\n•  It is the de-facto language used for the machine and \\ndeep learning framework Torch.\\nMatlab 1993 Multi-paradigm APL •  Solid Integrated environment. Matrix, linear algebra \\noriented language.\\n•  A selection of toolboxes and utilities for machine \\nlearning, statistics and signal processing.\\nProlog 1984 (procedural, \\nfunctional) Planner •  Good set of utilities for expressing the relationships \\nbetween objects and symbolic computation.\\n•  Large set of internal functionalities to perform logic \\nprogramming.\\nPython 1972 Procedural C++, java, \\nhaskell, perl•  Highly useful standard library that makes the language \\nversatile and flexible. Focus on rapid development.\\n•  Plethora of frameworks and utilities for AI, ML, deep \\nlearning, scientific computing, natural processing \\nlanguage etc. \\nR 1972 Declarative Lisp, Scheme •  Most comprehensive sets of statistical analysis \\nfunctions and packages.\\n•  Rich community of tools for AI or ML provided freely \\nthrough the CRAN repository.\\nScala 1993 Multiparadigm \\n(procedural, \\nfunctional)Erlan, Haskel, \\nJava, Lisp, Lisp \\n(Scheme)•  Fast run time (almost as C). It runs on top of the JVM. \\nVery good support for distributed systems.\\n•  Several libraries and frameworks for AI, ML and \\nnumerical computing (ScalaNLP).\\nArtificial Intelligence and Robotics  // 28\\nProgramming languages played a major role in the evolution \\nof AI since the late 1950s and  several teams carried \\nout important research projects in AI; e.g. automatic \\ndemonstration programs and game programs (Chess, \\nLadies) [65]. During these periods researchers found \\nthat one of the special requirements for AI is the ability \\nto easily manipulate symbols and lists of symbols rather \\nthan processing numbers or strings of characters. Since \\nthe languages of the time did not offer such facilities, a \\nresearcher from MIT, John MacCarthy, developed, during \\n1956-58, the definition of an ad-hoc language for logic \\nprogramming, called LISP (LISt Processing language).  \\nSince then, several hundred derivative languages,  so-called \"Lisp dialects\", have emerged (Scheme, Common \\nLisp, Clojure); Indeed, writing a LISP interpreter is not a hard \\ntask for a Lisp programmer (it involves only a few thousand \\ninstructions) compared to the development of a compiler \\nfor a classical language (which requires several tens of \\nthousands of instructions). Because of its expressiveness \\nand flexibility, LISP was very successful in the artificial \\nintelligence community until the 1990s. \\nAnother important event at the beginning of AI was the \\ncreation of a language with the main purpose of expressing \\nlogic rules and axioms. Around 1972 a new language was \\ncreated by Alain Colmerauer and Philippe Roussel named '),\n",
       " Document(metadata={'source': 'data/AI_Robotics.pdf', 'page': 35}, page_content='29 // Artificial Intelligence and Robotics\\nProlog (PROgramming in Logic). Their goal was to create  \\na programming language where the expected logical  \\nrules of a solution can be defined and the compiler \\nautomatically transforms it into a sequence of instructions. \\nProlog is used in AI and in natural language processing. Its \\nrules of syntax and its semantics are simple and considered \\naccessible to non-programmers. One of the objectives was \\nto provide a tool for linguistics that was compatible with \\ncomputer science. \\nIn the 1990s, the machine languages with C / C ++ and \\nFortran gained popularity and eclipsed the use of LISP \\nand Prolog. Greater emphasis was placed on creating \\nfunctions and libraries for scientific computation on these \\nplatforms and were used for intensive data analysis tasks \\nor artificial intelligence with early robots. In the middle of the \\n1990s, the company Sun Microsystems, started a project \\nto create a language that solved secutiry flaws, distributed \\nprogramming and multi-threading of C++. In addition, they \\nwanted a platform that could be ported to any type of device \\nor platform. In 1995, they presented Java, which took the \\nconcept of object orientation much further than C++.  \\nEqually, one of the most important additions to Java was \\nthe Java VM (JVM) which enabled the capability of running \\nthe same code in any device regardless of their internal \\ntechnology and without the need of pre-compiling for every \\nplatform. This added new advantages to the field of AI \\nthat were be introduced in devices such as cloud servers \\nand embedded computers. Another important feature of \\nJava was that it also offered one of the first frameworks, \\nwith specific tools for the internet, bringing the possibility \\nof running applications in the form of java applets and \\njavascripts (i.e. self-executing programs) without the need of \\ninstallation. This had an enormous impact in the field of AI \\nand a set the foundation in the fields of web 2.0/3.0 and the \\ninternet of things (IoT).\\nHowever, the development of AI using purely procedural \\nlanguages was costly, time-consuming and error prone. \\nConsequently, this turned the attention into other multi-\\nparadigm languages that could combine features from \\nfunctional and procedural object-oriented languages.  \\nPython, although first published in 1991, started to gain \\npopularity as an alternative to C/C++ with Python 2.2 by \\n2001. The Python concept was to have a language that \\ncould be as powerful as C/C++ but also expressive and \\npragmatic for executing \"scripts\" like Shell Script. It was \\nin 2008, with the publication of Python 3.0, which solved \\nseveral initial flaws, when the language started to be \\nconsidered a serious contender for C++, java and other \\nscripting languages such as Perl. Since 2008, the Python community has been trying to catch \\nup with specific languages for scientific computing, such \\nas Matlab and R. Due to its versatility, Python is now used \\nfrequently for research in AI. However, although python has \\nsome of the advantages of functional programming, run-time \\nspeeds are still far behind other functional languages, such \\nas Lisp or Haskell, and even more so from C/C++.  \\nIn addition, it lacks of efficiency when managing large \\namounts of memory and highly-concurrent systems.\\nFrom 2010 and mostly driven by the necessity of translating \\nAI into commercial products, (that could be used by \\nthousands and millions of users in real time), IT corporations \\nlooked for alternatives by creating hybrid languages, that \\ncombined the best from all paradigms without compromising \\nspeed, capacity and concurrency. In recent years, new \\nlanguages such as Scala and Go, as well as Erlang or \\nClojure, have been used for applications with very high \\nconcurrency and parallelization, mostly on the server side. \\nWell-known examples are Facebook with Erlang or Google \\nwith Go. New languages for scientific computation have also \\nemerged such as Julia and Lua. \\nAlthough functional programming has been popular in \\nacademia, its use in industrial settings has been marginal \\nand mainly during the times when “expert systems” were at \\ntheir peak, predominantly during the 1980s. After the fall of \\nexpert systems, functional programing has, for many years, \\nbeen considered a failing relic from that period. However, as \\nmultiprocessors and parallel computing are becoming more \\navailable, functional programming is proving to be a choice \\nof many programmers to maximise functionality from their \\nmulticore processors. These highly expensive computations \\nare usually needed for heavy mathematical operations or \\npattern matching, which constitute a fundamental part \\nof running an AI system. In the future, we will see new \\nlanguages that bring simplifications on existing functional \\nlanguages such as Haskell and Erlang and make this \\nprogramming paradigm more accessible. In addition, the \\nadvent of the internet-of-things (IoT) has drawn the attention \\nto the programming of embedded systems. Thus, efficiency, \\nsafety and performance are again matters for discussion. \\nNew languages that can replace C/C++ incorporating \\ntips from functional programming (e.g. Elixir) will become \\nincreasingly popular. Also, new languages that incorporate \\nsimplifications as well as a set of functions from modern \\nimperative programming, while maintaining a performance \\nlike C/C++ (e.g. Rust), will be another future development.'),\n",
       " Document(metadata={'source': 'data/AI_Robotics.pdf', 'page': 36}, page_content='Programming languages played a major role in the evolution of AI. \\nDriven by the necessity of translating AI into commercial products, \\nhybrid languages are emerging, which combine the best from all \\nparadigms without compromising speed, capacity and concurrency.\\nArtificial Intelligence and Robotics  // 30'),\n",
       " Document(metadata={'source': 'data/AI_Robotics.pdf', 'page': 37}, page_content='31 // Artificial Intelligence and Robotics\\nMachine vision integrates image capture and \\nanalysis with machine learning to provide \\nautomatic inspection, scene recognition and \\nrobot navigation. Scene reconstruction along  \\nwith object detection and recognition are the \\nmain sub-domains of machine vision.'),\n",
       " Document(metadata={'source': 'data/AI_Robotics.pdf', 'page': 38}, page_content='Artificial Intelligence and Robotics  // 32\\n11.  IMPACT OF MACHINE VISION\\nMachine vision integrates image capture systems with \\ncomputer vision algorithms to provide automatic inspection \\nand robot guidance. Although it is inspired by the human \\nvision system, based on the extraction of conceptual \\ninformation from two-dimensional images, machine vision \\nsystems are not restricted to 2D visible light. Optical sensors \\ninclude single beam lasers to 3D high definition Light \\nDetection And Ranging (LiDAR) systems, also known as \\nlaser scanning 2D or 3D sonar sensors and one or multiple \\n2D camera systems. Nevertheless, most machine vision \\napplications are based on 2D image-based capture systems \\nand computer vision algorithms that mimic aspects of \\nhuman visual perception. Humans perceive the surrounding \\nworld in 3D and their ability to navigate and accomplish \\ncertain tasks depends on reconstructing 3D information from \\n2D images that allows them to locate themselves in relation \\nto the surrounding objects. Subsequently, this information  \\nis combined with prior knowledge in order to detect and \\nidentify objects around them and understand how  \\nthey interact. Scene reconstruction along with object \\ndetection and recognition are the main sub-domains of \\ncomputer vision. \\nRegardless of the imaging sensors used, the most common \\napproaches of reconstructing 3D information are normally \\nbased on either time-of-flight techniques, multi-view \\ngeometry and/or on photometric stereo. The former is used \\nin laser scanners to estimate the distance between the \\nlight source and the object based on the time required for \\nthe light to reach the object and return back. Time-of-flight \\napproaches are used to measure distances in kilometres and they are accurate to a millimetre scale, since they are limited \\nby the ability to measure time. On the other hand, multi-view \\ngeometry problems include ‘structure’ problems, ‘stereo \\ncorrespondence’ problems and ‘motion’ problems. Recovery \\nof the 3D ‘structure’ implies that given 2D projections of the \\nsame 3D point, in two or more images, the 3D coordinates \\nof the point are estimated based on triangulation. ‘Stereo \\ncorrespondence’ refers to the problem of finding the image \\npoint that corresponds to a point from another 2D view. \\nFinally, ‘motion’ refers to the problem of recovering the \\ncamera coordinates given a set of corresponding points \\nin two or more image views. 3D laser scanners based \\non triangulation can reach micrometre accuracy but their \\nrange is constrained to a few meters. Several sub-problems \\nsuch as ‘structure from motion’ uses multi-view geometry \\nprinciples to extract corresponding points between 2D views \\nof the same object and reconstruct its shape.\\nStereo-vision assumes the robust extraction of corresponding \\nsalient points/features across images, the so-called interest \\npoint detection. These features should be invariant to \\nphotometric transformation such as changes in the lighting \\nconditions and covariant to geometric transformations. \\nFor over two decades researchers have proposed several \\napproaches. The Scale-invariant feature transform (SIFT) \\nextracts features that are invariant to scale, rotation and \\ntranslation transformations and robust to illumination \\nvariations and moderate perspective transformations.  \\nSince its introduction in 1999-2004, it has been successful  \\nin several vision applications, including object recognition, \\nrobot localisation and mapping. '),\n",
       " Document(metadata={'source': 'data/AI_Robotics.pdf', 'page': 39}, page_content=\"33 // Artificial Intelligence and Robotics\\nRepresenting and recognising object categories have proven \\nmuch harder problems to generalise and solve, compared \\nwith 3D reconstruction, since there are thousands of \\nobjects that can belong to an arbitrary number of categories \\nsimultaneously. Several ideas about object detection are \\nrelated to Gestalt psychology, which is a theory of mind \\nwith relation to visual perception. A major aspect of the \\ntheory is about grouping entities together based on their \\nproximity, similarity, symmetry, common fate, continuity and \\nso on. From the 1960s to early 1990s, research in object \\nrecognition was centred on geometric shapes. This was a \\nbottom-up process, which uses a small number of primitive \\n3D dimensional objects that are assembled together in \\nvarious configurations to form complex objects. In the 1990s, \\nappearance-based models were explored, which were based \\non manifold learning of the object appearance parameterised \\nby the pose and illumination [66]. These techniques are not \\nrobust to occlusion, clutter and deformation. By the mid-\\nlate 1990s, sliding window approaches were designed that \\nclassify whether an object is found for each instance of a \\nsliding window across an image [67]. The main challenges \\nwere how to design features that represent appropriately the \\nappearance of the object and how to efficiently search a large \\nnumber of positions and scales. Local features approaches \\nwere also developed and they aimed towards those which \\nwere invariant to image scaling, geometric transformations \\nand illumination changes [68]. In the early 2000s 'parts-and-\\nshape' models along with 'bags of features' were suggested. \\nParts-and-shape models represent complex objects using combinations of multi-scaled deformable objects [69].  \\nOn the other hand, bags of features methods, represent \\nvisual features as words and relate object recognition and \\nimage classification to the expressive power of natural \\nlanguage processing approaches [70].\\nMachine learning in object recognition facilitated a shift, from \\nsolving a problem based on mathematical modelling alone, \\nto learning algorithms based on real-data and statistical \\nmodelling. A major breakthrough in object recognition and \\nclassification came in 2012 with the emergence of deep \\nneural networks and the availability of large labelled image \\ndatabases, such as ImageNet. Compared to classical object \\nrecognition methods, which depend on feature extraction \\nfollowed by feature matching methodologies, deep learning \\nhas the advantage of encoding both feature extraction and \\nimage classification via the structure of a neural network.  \\nThe superb performance of deep neural networks resulted \\nin an increase of image classification from 72% in 2010 to \\n96% in 2015, which outperforms human accuracy and has \\nhad a significant impact in real-life applications [71]. Both \\nGoogle and Baidu updated their image search capabilities \\nbased on the Hinton’s deep neural network architecture. Face \\ndetection has been introduced in several mobile devices and \\nApple even created an app to recognise pets. The accuracy \\nof these models in object recognition and image classification \\nexceed human-level accuracy and spread waves of \\ntechnological changes across the industry.\"),\n",
       " Document(metadata={'source': 'data/AI_Robotics.pdf', 'page': 40}, page_content=\"Artificial Intelligence and Robotics  // 34\\n2012-present Deep Neural Networks in Image \\nClassification:  DNNs are trained with big image \\ndatasets such as ImageNet and currently have \\nexceeded human abilities in object/face recognition \\n(Krizhevsky et al. 2012).\\n2004 Real-time face detection:  Machine \\nlearning approach of sliding-window based object \\nrecognition for robust face detection has been \\nintroduced (Viola et al. 2004). \\n2002 Active stereo with structured light:  Zhang \\net al. introduced the idea of using light patterns to \\nestimate robust correspondence between a pair of \\nimages.\\n2001 Bag of words in computer vision:  \\nRepresenting visual features as words to allow \\nnatural language processing information retrieval to \\napply in object recognition and image classification \\n(Leung et al. 2001).\\n1999 Scale-Invariant Feature Transform (SIFT):  \\nDavid Lowe patented an algorithm to detect and \\ndescribe local features in images. SIFT features \\nare invariant to uniform scaling, orientation and \\nillumination changes. \\nEarly 1990s Simultaneous Localisation and \\nMapping (SLAM):  Leonard and Durrant-whyte \\npioneered a probabilistic method for handling \\nuncertainty of noisy sensor readings and allows \\nautonomous vehicles to localise themselves \\n(Leonard et al. 1991).\\n1981 Computational Stereo:  Grimson presented \\nthe theory of computational stereo vision that is \\nbiologically plausible. \\n1980 Photometric Stereo:  Woodham presented \\na method to extract surface normals from multiple \\nimages based on smoothness constrained posed \\nby the illumination model. \\nKhandelwal et al. The International Journal of Robotics \\nResearch, 2017\\nKrizhevsky et al. Advances in neural networks, 2012\\nLeonard et al. Intelligent Robots and Systems, 1991\\nLeung et al. International Journal of Computer Vision 2001\\nViola et al. Interantional Journal of Computer Vision 2004\\n2017 BWIBots:  Vision robots learn the human's \\npreferences and how to cooperate by working side \\nby side with humans (Khandelwal et al. 2017).\\n2009 Kinect:  Microsoft announced a device \\nthat used structured-light computational stereo \\ntechnology to track body’s posture. Within 60 days, \\nit sold 8 million units and claimed the Guinness \\nWorld Record of the ‘fastest selling consumer \\nelectronics device’.\\n2001 Hawk-Eye:  A real-time vision system with \\nmultiple high-performance cameras for providing a \\n3D representation of the trajectory of a ball using \\ntriangulation. \\n1997 Nomad robot:  Autonomous used to search \\nAntarctic meteorites based on advanced perception \\nand navigation technologies developed at Carnegie \\nMellon University. \\n1974 Bayer filter camera:  Bryce Bayer, an \\nAmerican scientist working for Kodak, captured \\nvivid colour information onto a digital image.\\n1969 Charge-Couple Device (CCD):  CCD \\nwas invented at American Bell Laboratories by \\nWilliam Boyle and George E. Smith. CCD is the \\nmajor technology for digital imaging as it converts \\nincoming photons into electron charges.\\n1963 Complementary Metal-Oxide-\\nSemiconductor (CMOS):   Frank Wanlass, an \\nAmerican electrical engineer patented CMOS used \\nin digital logic circuits as well as analogue circuits \\nand image sensors.\\n1914 Optical Character Reader (OCR):  Goldberg \\ninvented a machine that could read characters and \\nconvert them into standard telegraph code. IMAGING DEVICES/HARDWARE     COMPUTER VISION/CONCEPTS    \\nFigure 10\\nA timeline of Computer Vision and AI.\"),\n",
       " Document(metadata={'source': 'data/AI_Robotics.pdf', 'page': 41}, page_content='35 // Artificial Intelligence and Robotics\\nThe development of AI is closely coupled with our \\npursuit of understanding the human brain. A long-term \\ngoal of computational neuroscience is to emulate the \\nbrain by mimicking the causal dynamics of its internal \\nfunctions so that the models relate to the brain function.'),\n",
       " Document(metadata={'source': 'data/AI_Robotics.pdf', 'page': 42}, page_content='Artificial Intelligence and Robotics  // 36\\nThe development of AI is closely coupled with our pursuit \\nof understanding the human brain. A long-term goal of \\ncomputational neuroscience is to emulate the brain by \\nmimicking the causal dynamics of its internal functions so \\nthat the models relate to the brain functions in human/animal \\nbehaviour characteristics [72]. Although there is a lot of \\nexcitement that this approach would help understand how \\nintelligent behaviour emerges, there is also heated debate on \\nwhether this is a realistic goal as we do not fully understand \\nhow the brain works [73, 74]. The human brain is highly \\ncomplex with more than 80 billion neurons and trillion of \\nconnections. Simulation scales can range from molecular \\nand genetic expressions to compartment models of \\nsubcellular volumes and individual neurons to local networks \\nand system models. \\nDeep Neural Network nodes are an oversimplification \\nof how brain synapses work. Signal transmission in the \\nbrain is dominated by chemical synapses, which release \\nchemical substances and neurotransmitters to convert \\nelectrical signals via voltage-gated ion channels at the \\npresynaptic cleft into post-synaptic activity. The type of \\nneurotransmitter characterises whether a synapse facilitates \\nsignal transmission (excitatory role) or prevents it (inhibitory \\nrole). Currently, there are tenths of known neurotransmitters, \\nwhereas new ones continuously emerge with varying \\nfunctional roles. Furthermore, dynamic synaptic adaptations, \\nwhich affect the strength of a synapse, occur in response \\nto the frequency and magnitude of the presynaptic signal \\nand reflect complex learning/memory functions, (Spike \\ntime dependent plasticity). Recently, evidence has found \\nthat surrounding cells, such as glia cells that are primarily \\ninvolved in ‘feeding’ the neurons, can also affect their \\nfunction via the release of neurotransmitters. \\nThe earliest and most elaborate attempts for modelling \\nneuronal complexity are based on conductance-based \\nbiophysical models of synaptic interaction (COBA) and \\nspike generation, such as the Hodgkin-Huxley (HH) model. \\nSeveral popular software platforms, such as GENESIS and \\nNEURON, exploit COBA models to develop systematic \\nmodelling approaches of realistic brain networks. Simpler \\nmodels, such as integrate-and-fire, are faster to simulate \\nand they are also used in large-scale simulations when the \\ndynamics of spike generation are less important. \\nIt is evident that the computational complexity of the brain \\nnetworks depends not only on the number of neurons and \\nsynapses but also on the topology of the network and the level of biological details it describes. The mammalian \\ncerebral cortex is organised intuitively to minimise wiring. \\nGroup of neurons form cortical columns, which encode \\nfunctionally similar features and they are considered the \\nsmallest functional brain units from where consciousness \\nemerges. In fact the major objective of the Blue Brain \\nproject, a leading research project on computational \\nneuroscience, started in 2005, was to emulate the rat \\nneocortical columns of around 10,000 neurons and  \\n108 synapses. \\nCurrently, there is a trend toward developing neuromorphic \\nhardware circuits to allow near real-time large-scale \\nsimulations of neural networks [75]. The neuromorphic term \\nrefers to mimicking the structure of neurons (dendrites, \\naxon and synapse) to achieve functional equivalence. For \\nexample, the Neurogrid is a neuromorphic supercomputer, \\ndeveloped at Stanford, which combines analogue dendritic \\ncomputation (presynaptic ion-channel function) with digital \\naxonal communication. Each chip integrates one million \\nneurons interconnected with 256 million synapses. Analog \\nimplementations are more directly related to synaptic activity \\nand thus maximise energy efficiency and allow emulation \\nof a greater number of neurons and synapses. On the \\nother hand, digital implementations are more flexible to \\nreconfigure and allow storage of connectional weights with \\ngreater precision. One of the most promising technologies \\nin this area is the memristors, which has the ability to \\nsimultaneously perform logical and storage operations. \\nSimilar to neural synapses, the more current that flows \\nthrough a memristor, the more it can flow. Therefore, it can \\nmodel several biological functions including COBA synaptic \\ninteractions time varying delayed networks and spike-\\ntiming-dependent plasticity. Memristors have the potential to \\nreplace the existing digital/analog neuromorphic chips with \\nmuch more efficient and versatile technology. \\nWith the current exponential growth in the efficiency and \\nflexibility of neuromorphic hardware, the ability to make a \\ncomputer as fast and as complex as the human brain is \\nbecoming increasingly possible. Several large simulations  \\nof the brain are aimed to mainly replicate the cortical \\ndynamics obtained in in-vivo and in-vitro key neuroscience \\nstudies and validate cognitive theories and hypothesis.  \\nThe big question is if this would result in a conscious, \\nintelligent creature and how we would be able to detect this \\nin the very beginning without a thorough understanding of \\nwhat consciousness or intelligence is.12.  ARTIFICIAL INTELLIGENCE AND THE BIG BRAIN'),\n",
       " Document(metadata={'source': 'data/AI_Robotics.pdf', 'page': 43}, page_content='37 // Artificial Intelligence and Robotics\\n2015-present NeuroRobotics, Human Brain \\nProject: Robotic systems interfaced with brain \\nmodels for closed loop cognitive experiments in \\nsimulated environment.\\n2015 Somatosensory cortex of the juvenile \\nrat - Blue Brain Project & Human Brain Project:  \\nFirst digital reconstruction of the microcircutiry of \\nthe somatosensory cortex of juvenile rat. The study \\naimed to study detailed cortical dynamics and \\nreproduced in vitro and in vivo experimental results \\n(Markram, Muller et al. 2015).\\n2013 Human Brain Project:  It is an EU-funded \\nresearch project that aims to advance knowledge \\nin the fields of neuroinformatics, brain simulation, \\nneuromorphic computing and neurorobotics. \\n2012-present Spaun – University of Waterloo, \\nCanada:  First computer model to produce complex \\nbehaviour and achieve human performance \\nin simple tasks. It ran on Nengo platform and \\nmodelled brain function in a biologically realistic \\nscale (Eliasmith, Stewart et al. 2012).\\n2005-8 Thalamo-cortical Model – The \\nNeurosciences institute, San Diego, USA:  \\nSimulation of thalamo-cortical dynamics with of a \\nneural network that represents 300-by-300 mm2 \\nmammalian thalamo-cortical surface.  \\nOne second of simulation took 50 days to run \\n(Izhikevich and Edelman 2008).\\n2005-present Nengo – University of Waterloo, \\nCanada:  Open source software that provides tools \\nto specify the collective function of large groups of \\nneurons along with low-level electrophysiological \\ndetails.\\n2017 STDP via ferroelectric solid-state \\nsynapses, (memristors):  Thin ferroelectric layer \\nwithin two electrodes of which one can adjust \\nthe resistance by means of the voltage pulses to \\nemulate spike-timing-dependent plasticity (Boyn, \\nGrollier et al. 2017).\\n2014-present Neurogrid – Stanford:  A \\nneuromorphic supercomputer combines \\nanalogue dendritic computation with digital axonal \\ncommunication. Each chip integrates 1 million \\nspiking neurons and 256 million synapses.\\n2014 TrueNorth – IBM & SyNAPSE (Systems \\non Neuromorhpic Adaptive Plastic Scalable \\nElectronics):  The first neuromorphic integrated \\ncircuit to achieve one million individually \\nprogrammable neurons with 256 individually \\nprogrammable synapses.\\n2013 The BRAIN Initiative (Brain \\nResearch through Advancing Innovative \\nNeurotechnologies): A US initiative that aimed to \\ndevelop technologies to understand brain function. \\n2009-present SpiNNaker– University of \\nManchester: Massive parallel computer \\narchitecture composed by billion computing \\nelements communicating using stochastic spike \\nevents. It is based on a neuromorphic architecture \\nof six layers thalamocortical model and ‘unreliable’/\\nstochastic communication. \\n2006 Silicon Retina – Stanford:  The first artificial \\nretina constructed in silico to reproduce the \\nresponses of the four major ganglion cell types \\nthat drive visual cortex, producing 3600 spiking \\noutputs. It paved the way of a neural prosthesis \\nthat matches the dimensions of biological retina \\n(Zaghloul and Boahen 2006).\\n2006 Cortical columns modelling - IBM & \\nBlue Brain Project:  Run on an IBM Blue Gene/P \\narchitecture to model cortical minicolumns, \\nconsisting of 22 million 6-compartment neurons, \\nwith 11 billion synapses, with spatial delays \\ncorresponding to a 16 cm2 cortex surface and \\na simulation length of one second real-time.  \\n(Lundqvist, Rehn et al. 2006).MODELS/SOFTWARE PLATFORMS                                           HARDWARE'),\n",
       " Document(metadata={'source': 'data/AI_Robotics.pdf', 'page': 44}, page_content='Artificial Intelligence and Robotics  // 38\\nFigure 11\\nTimeline of AI and the Big Brain.\\n2005 The Blue Brain Project:  A Swiss brain \\ninitiative that aimed to realistically simulate the \\nmammalian brain. \\n1990-present NEURON – Yale & Duke\\n1985-present GENESIS (General NEural \\nSImulation System) – Caltech  Common open-\\nsource software simulation platforms that provides \\nCOBA models of synaptic interaction and plasticity. \\n2005-2015 IBM Blue Gene:  A series of \\nsupercomputers that aimed to reach the \\nperformance of one petaflop. In 2009, the project \\nwas awarded the National Medal on Technology \\nand Innovation. The latest model, Blue Gene/Q, \\nconsists of 18 core chips with a 64-bit A2 \\nprocessor cores and it has peak performance of 20 \\nPetaflops.\\nBoyn et al. 2017 Nature Communications\\nEliasmith et al. 2012 Science\\nIzhikevich et al. 2008 PNAS\\nLundqvist et al. 2006 Network Computation  \\nin Neural Systems\\nMarkram et al. 2015 Cell\\nNiebur et al. 1993 Mathematical Biosciences\\nZaghloul et al. 2006 Journal of Neural Engineering'),\n",
       " Document(metadata={'source': 'data/AI_Robotics.pdf', 'page': 45}, page_content=\"Has used armed drones\\nOwns armed dronesDeveloping armed drones\\nFigure 12 \\nCountries using, owning or developing armed drones\\n39 // Artificial Intelligence and Robotics\\n13. ETHICAL AND LEGAL QUESTIONS OF AI\\nThreat to Privacy  \\nData is the “fuel” of AI and special attention needs to be \\npaid to the information source and if privacy is breached. \\nProtective and preventive technologies need to be \\ndeveloped against such threats. Although solutions to this \\nissue may be unconnected to the AI operation per se, it \\nis the responsibility of AI operators to make sure that data \\nprivacy is protected. Additionally, applications of AI, which \\nmay compromise the rights to privacy, should be treated \\nwith special legislation that protects the individual.\\nThreats to security and weaponisation of AI\\nWith the proliferation of security risks, such as terrorism \\nand regional conflicts, we are immersed in a global arms \\nrace that has developed a demand for new weapons \\npowered by AI, such as autonomous drones and missiles, \\nas well as virtual bots and malicious software aimed at \\nsophisticated espionage. This could lead to the possibility \\nof an unprecedented war escalation. The danger of AI is \\nthat we could potentially lose control over it. This has led \\nassociations and non-governmental organizations (NGOs)  \\nto carry out awareness-raising actions to contain the use  \\nof these military robots and potentially ban the use of  \\nsuch weapons. The US military has just released a prospective document \\nentitled ‘Robotic and Autonomous Systems Strategy’, which \\ndetails its strategy for robotics and autonomous systems. \\nThe use of robotics and autonomous systems by the US \\nmilitary defines the following five objectives: 1) Increase \\nknowledge abilities in operations’ theatres, 2) Reduce \\nthe amount of charge carried by the soldier; 3) Improve \\nlogistics capacity; 3) Facilitate movement and manoeuvring; \\n4) Increase the protection of forces. Although offensive \\ncapacity is not mentioned, the four points introduced by  \\nthe US military are ambiguous with respect to their scope \\nand limitations.\\nEconomics and Employment Issues  \\nCurrently, 8% of jobs are occupied by robots, but in 2020 \\nthis percentage will rise to 26%. Robots will become \\nincreasingly autonomous and be able to interact, execute \\nand make more complex decisions. Thanks to 'big data', \\nrobots now have a formidable database that allows them to \\nexperiment and learn which algorithms work best.  \\nThe accelerated process of technological development  \\nnow allows labor to be replaced by capital (machinery). \\nHowever, there is a negative correlation between the \\nprobability of automation of a profession and its average \\nannual salary, suggesting a possible increase in short-term \\ninequality [76]. The problem is not the number of jobs lost \\nthrough automation, but in creating enough to compensate \\nfor potential job losses. In previous industrial revolutions, \\nnew industries hired more people than those who lost their \\njobs in companies that closed, because they could not \\ncompete with the speed of development in new technologies \\n[77]. An important note, about this revolution, is the fact that \\nit is not only the manual trades likely to be automated, but \\nalso in jobs involving tasks of an intermediate nature, such \\nsecretarial, administration and other office work. To deal with \\nthis situation, it is necessary to put in place legal frameworks \\nthat make sure the benefits of automation do not solely go \\nto the employer but are distributed equally, to guarantee the \\nmaintenance of education, health and pensions. \\nHuman Bias in Artificial Intelligence  \\nIn an article published by Science magazine, researchers \\nsaw how machine learning technology reproduces human \\nbias, for better or for worse. Words related to the lexical \\ndomain of flowers are associated with terms related to \\nhappiness and pleasure (freedom, love, peace, joy, paradise, \\netc.). The words relating to insects are, conversely, close to \\nnegative terms (death, hatred, ugly, illness, pain, etc.).  13.1 ETHICAL ISSUES IN ARTIFICIAL INTELLIGENCE\"),\n",
       " Document(metadata={'source': 'data/AI_Robotics.pdf', 'page': 46}, page_content='Artificial Intelligence and Robotics  // 40\\nThis reflects the links that humans have made themselves.  \\nAI biases have already been highlighted in other applications. \\nOne of the most notable was probably Tay, a Microsoft \\nAI launched in 2016, which was supposed to embody a \\nteenager on Twitter, able to chat with internet users and \\nimprove through conversations. However, in just a few hours, \\nthe program, learning from its exchanges with humans, \\nbegan to make racist and anti-Semitic remarks, before  \\nbeing suspended by Microsoft (see Sidebar – Failures of \\nAI). The problem is not only at language level. When an AI \\nprogram became a juror in a beauty contest in September \\n2016, it eliminated most black candidates as the data on \\nwhich it had been trained to identify “beauty” did not contain \\nenough black skinned people.  \\n13.2 LEGAL ISSUES AND QUESTIONS OF AI\\n \\nLegal Responsibility  \\nInitially, the legal framework that would apply to robots \\nand AI would have the purpose of limiting the risks derived \\nfrom the operation of these systems and limit the damage \\nthat could occur from unintended consequences with their \\noperation. AI could not have constitutional rights, as these \\nare the property of individuals, but can have some property \\nrights, in order to guarantee their possible liability for any \\ndamage caused. For this reason they could have some form \\nof judicial protection. In this case, robots and AI would be \\nsubject to two types of responsibility: 1) Predictability in their \\nactions; and 2) civil liability in any harmful consequences of \\ntheir actions (although there is also a fiscal responsibility as  \\na consequence of non-compliance with the obligations of \\nthis type). \\nThe European Parliament is already working on a \\nRecommendations Report (2015/2103, dated 31 May \\n2016) on civil law on robotics, which provides guidelines for \\nregulating civil liability arising from the use of robots [78]. It \\nrefers to the contractual and non-contractual responsibilities \\nthat may derive from its action and recommends that this \\nliability be defined as an objective as well as establishing \\nthe need to have compulsory insurance for civil liability, for \\nany damages arising from the possession and use of such \\nrobots. That means that in the event of an accident, the \\nreport proposes a compulsory insurance scheme, a policy \\nidentical to that of automobiles. The manufacturers will have \\na contractual obligation to compensate possible victims and \\nto consolidate a fund to protect against robot accidents. The report also considers the effect of “short-circuits”,  \\nto protect humans from any accidents or aggression.  \\nThis does not mean that the responsibility of man will be \\nentirely negated but rather a sliding scale could be created: \\nthe more sophisticated a robot is, the more responsibility  \\nthe designer would bear. \\nIn view of the recent government policy, autonomous \\nmachines (cars without drivers, drones, medical devices)  \\nwill soon have civil liability. Autonomous machines must have \\na name, a first name and a registration number. In the event \\nof an accident, identification will be aided with some kind of  \\ncivil status. \\nCivil Rights for AI and Robots  \\nRobots, to the extent that they are autonomous, could \\nbe granted the status of electronic persons with specific \\nrights and obligations. There are also calls to harmonize the \\ncohabitation between robots and humans. For instance, \\ndomestic robots are sort of “intimate gadgets”. They create \\nthe notion of empathy with the humans they interact with \\non a daily basis. A legal framework would make it possible \\nto crystallize this particular type of relationship in law. In \\ncomparison with domestic animals, whose legal status \\nwas clarified in January 2015, can be drawn here. There is \\nhowever a distinction in that, unlike animals, robots are not \\nbiologically alive and have no sensitivity. However, they are \\nstill endowed with an intelligence that can be superior to one \\nof an animal. The idea of providing AI systems and robots \\na set of rights, such as ones provided to domestic animals, \\nrequires an understanding of how machines could process \\ntheir own feelings and emotions, if machines are equipped in \\nfuture with some sort of emotional intelligence.\\nFrom the point of view of the labour market, the use of \\nrobots will mean the disappearance of certain jobs that,  \\nuntil now, have been performed by humans. To reduce  \\nthe social impact of unemployment caused by robots  \\nand autonomous systems, the EU parliament proposed \\nthat they should pay social security contributions and taxes \\nas if they were human. By producing a surplus value from \\ntheir work, they generate an economic benefit. It is one of \\nthe more controversial points in the proposals of the EU \\nRobotics Report.'),\n",
       " Document(metadata={'source': 'data/AI_Robotics.pdf', 'page': 47}, page_content='41 // Artificial Intelligence and Robotics\\nAI has the potential to change the world but there are \\nstill many problems to overcome before its widespread \\napplications. Furthermore, its practical use is not without \\nfailures (see Fig 13, Example Failures of AI). Recently, \\nwe have seen a surge of interest in deep learning with \\npromising results that will reshape the future of AI. But deep \\nlearning is only one of the many tools that the AI community \\nhas developed over the years. It is important to put into \\nperspective the current development of AI and its specific \\nlimitations.\\nIntelligence as a multi-component model:  A machine to be \\ncalled “intelligent” should satisfy several criteria that include \\nthe ability of reasoning, building models, understanding \\nthe real word and anticipate what might happen next. The \\nconcept of “intelligence” is made of the following high-level \\ncomponents: perception, common sense, planning, analogy, \\nlanguage and reasoning. \\nLarge datasets and hard generalisation:  After extensive \\ntraining on big datasets, today machines can achieve \\nimpressive results in recognising images or translating \\nspeech. These abilities are obtained thanks to the derivation \\nof statistical approximations on the available data. However, \\nwhen the system has to deal with new situations when \\nlimited training data is available, the model often fails. We \\nknow that humans can perform recognition even with small \\ndata since we can abstract principles and rules to generalise \\nto a diverse range of situations. The current AI systems are \\nstill missing this level of abstraction and generalisability. \\nBlack box and a lack of interpretation:  Another issue \\nwith the current AI system is the lack of interpretation. For \\nexample, deep neural networks have millions of parameters \\nand to understand why the network provides good or bad \\nresults becomes impossible. Despite some recent work on \\nvisualising high-level features by using the weight filters in a \\nconvolution neural network, the obtained trained models are \\noften not interpretable. Consequently, most researchers use \\ncurrent AI approaches as a black box.Robustness of AI:  Most current AI systems can be easily \\nfooled, which is a problem that affects almost all machine \\nlearning techniques. \\nDespite these issues, it is certain that AI will play a major role \\nin our future life. As the availability of information around us \\ngrows, humans will rely more and more on AI systems to \\nlive, to work and to entertain. Therefore, it is not surprising \\nthat large tech firms are investing heavily on AI related \\ntechnologies. In many application areas, AI systems are \\nneeded to handle data with increasing complexities. Given \\nincreased accuracy and sophistication of AI systems, they \\nwill be used in more and more sectors including finance, \\npharmaceuticals, energy, manufacturing, education, \\ntransport and public services. In some of these areas they \\ncan replace costly human labour and create new potential \\napplications and work along with/for humans to achieve \\nbetter service standards. It has been predicted that the next \\nstage of AI is the era of augmented intelligence. Ubiquitous \\nsensing systems and wearable technologies are driving \\ntowards intelligent embedded systems that will form a \\nnatural extension of human beings and our physical abilities. \\nHuman sensing, information retrieval and physical abilities \\nare limited in a way that AI systems are not. AI algorithms \\nalong with advanced sensing systems could monitor \\nthe world around us and understand our intention, thus \\nfacilitating seamless interaction with each other. \\nAdvances in AI will also play a critical role in imitating the \\nhuman brain function. Advances in sensing and computation \\nhardware will allow to link brain function with human \\nbehaviour at a level that AI self-awareness and emotions \\ncould be simulated and observed in a more pragmatic \\nway. Recently, quantum computing has also attracted a \\nnew wave of interest from both academic institutions and \\ntechnological firms such as Google, IBM and Microsoft. \\nAlthough the field is at its infancy and there are major \\nbarriers to overcome, the computational power it promises, \\npotentially relevant to the field of AI, is well beyond our \\nimagination. 14. LIMITATIONS AND OPPORTUNITIES OF AI '),\n",
       " Document(metadata={'source': 'data/AI_Robotics.pdf', 'page': 48}, page_content='Figure 13 \\nExample failures of AI\\nArtificial Intelligence and Robotics  // 42\\n2016:  Artificial intelligence fails to beat real stupidity. \\nMicrosoft lunched Tay, an AI Twitter bot that just \\nafter 24 hours turned into a racist, Hitler-lover, \\nincestual sex-promoting robot. Tay was developed \\nto learn by interacting with people, but it failed to \\ncater for the darker side of human. \\n2016:  Tesla driver dies while using autopilot mode. \\nA driver died in the first fatal crash involving a \\nself-driving car. The car’s vision system failed to \\ndistinguish a large truck and trailer crossing the \\nhighway at full speed.\\n2016:  Robots failed in their duties and lost their \\njobs. Three restaurants in China fired their robot \\nwaiters. The robots broke down continuously,  \\ntwo of the restaurants have closed and the third \\nre-hired humans. \\n2016:  Service robot caused traffic jams. Promobot, \\na humanoid robot, was designed for promoting \\nproducts or conduct surveys. It has created many \\ntraffic jams after escaping from its lab and it was \\nalso arrested while it was collecting voter opinions \\nfor political candidates to gain unfair advantage. \\n1983:  Nuclear attack early warning system falsely \\nclaimed that an attack is taking place. A nuclear \\nwarning system of the Soviet Union reported the \\nlaunch of a ballistic missile from the United States. \\nThis was a false alarm that it could have cause a \\nnuclear attack and an immediate escalation of the \\ncold-war to a full-scale nuclear war. \\n1966  Mistranslations DARPA funded a project  \\nto translate Soviet documents into English.  \\nIt was a clear failure and after spending $20 million, \\nit was closed.\\n2016:  Search engine AI highly ranks fake news.  \\nThe highly ranked entry of the Google search \\nengine on the query ”Did the Holocaust happen” \\nwas a neo-Nazi and denial website. Since that, \\nGoogle has tried to improve their AI search engine \\nto provide authoritative results.\\n2016:  Fatty the robot smashes glass and injures \\nvisitor. During a demonstration in China, a robot \\ncalled Fatty piercing a bystander’s ankle after broke \\nthe glass of a booth. There hasn’t been much \\ninformation about Fatty since the incident. \\n2016:  Facial recognition rejected a legitimate \\ncitizens. An AI face recognition software used in the \\nadministration office of New Zealand, rejected an \\nAsian citizen since it mistakenly registered his eyes \\nas being closed. Currently, it is estimated that 20% \\nof faces are still mistakenly classified. \\n2015:  Adult content filtering software failed to \\nremove inappropriate content. Google’s new \\nYouTube Kids app failed to remove “inappropriate \\ncontent,” including explicit sexual language and \\njokes about paedophilia.\\n1980:  The Fifth Generation Computer Systems.  \\nA government/industry research project in \\nJapan aimed to create a computer using parallel \\ncomputing. After 10 years of research and $400 \\nmillion, the project was terminated without having \\nmet its goals to provide a platform for future \\ndevelopments in AI.'),\n",
       " Document(metadata={'source': 'data/AI_Robotics.pdf', 'page': 49}, page_content='43 // Artificial Intelligence and Robotics\\nThere are many lessons that can be learnt from the past \\nsuccesses and failures of AI. To sustain the progress of \\nAI, a rational and harmonic interaction is required between \\napplication specific projects and visionary research ideas. \\nAlong with the unprecedented enthusiasm of AI, there are \\nalso fears about the impact of the technology on our society. \\nA clear strategy is required to consider the associated ethical \\nand legal challenges to ensure that the society as a whole \\nwill benefit from the evolution of AI and its potential adverse \\neffects are mitigated from early on. Such fears should not \\nhinder the progress of AI but motivate the development of a \\nsystematic framework on which future AI will flourish. Most \\ncritical of all, it is important to understand science fiction \\nfrom practical reality. With sustained funding and responsible \\ninvestment, AI is set to transform the future of our society - \\nour life, our living environment and our economy. \\nThe following recommendations are relevant to the UK \\nresearch community, industry, government agencies and \\npolicy makers: \\n•  Robotics and AI are playing an increasingly important \\nrole in the UK’s economy and its future growth. We need \\nto be open and fully prepared for the changes that they \\nbring to our society and their impact on the workforce \\nstructure and a shift in the skills base. Stronger national \\nlevel engagement is essential to ensure the general public \\nhas a clear and factual view of the current and future \\ndevelopment of robotics and AI.•  A strong research and development base for robotics and \\nAI is fundamental to the UK, particularly in areas in which \\nwe already have a critical mass and international lead. \\nSustained investment in robotics and AI would ensure the \\nfuture growth of the UK research base and funding needs \\nto support key Clusters/Centres of Excellence that are \\ninternationally leading and weighted towards projects with \\ngreater social-economic benefit.\\n•  It is important to address legal, regulatory and ethical \\nissues for practical deployment and responsible \\ninnovation of robotics and AI; greater effort needs to \\nbe invested on assessing the economic impact and \\nunderstanding how to maximise the benefits of these \\ntechnologies while mitigating adverse effects.\\n•  The government needs to tangibly support the workforce \\nby adjusting their skills and business in creating \\nopportunities based on new technologies. Training in \\ndigital skills and re-educating the existing workforce is \\nessential to maintain the competitiveness of the UK. \\n•  The UK has a strong track record in many areas of RAS \\nand AI. Sustained investment in robotics and AI is critical \\nto ensure the future growth of the UK research base and \\nits international lead. It is also critical to invest in and \\ndevelop the younger generation to be robotics and AI \\nsavvy with a strong STEM foundation by making effective \\nuse of new technical skills.15. CONCLUSION AND RECOMMENDATIONS\\n'),\n",
       " Document(metadata={'source': 'data/AI_Robotics.pdf', 'page': 50}, page_content='Artificial Intelligence and Robotics  // 44\\nREFERENCES\\n[1]  S. J. Russell and P . Norvig, Artificial intelligence: a modern \\napproach (3rd edition): Prentice Hall, 2009.\\n[2]  I. Lighthill, \"Artificial Intelligence: A General Survey,\" in Artificial \\nIntelligence: A Paper Symposium. London: Science Research \\nCouncil, 1973.\\n[3] M. Minsky and S. Papert, \"Perceptrons,\" 1969.\\n[4]  J. J. Hopfield, \"Neural networks and physical systems with \\nemergent collective computational abilities,\" Proceedings of \\nthe national academy of sciences, vol. 79, pp. 2554-2558, \\n1982.\\n[5]  D. E. Rumelhart, G. E. Hinton, and R. J. Williams, \"Learning \\ninternal representations by error propagation,\" DTIC \\nDocument1985.\\n[6]  M. Wooldridge and N. R. Jennings, \"Intelligent agents: Theory \\nand practice,\" The knowledge engineering review, vol. 10, pp. \\n115-152, 1995.\\n[7]  L. A. Zadeh, \"Fuzzy logic—a personal perspective,\" Fuzzy \\nSets and Systems, vol. 281, pp. 4-20, 2015.\\n[8]  N. Spinrad, \"Mr Singularity,\" Nature, vol. 543, pp. 582-582, \\n2017.\\n[9]  E. Horvitz, \"One Hundred Year Study on Artificial Intelligence: \\nReflections and Framing,\" ed: Stanford University, 2014.\\n[10]  S. Lohr, \"The age of big data,\" New York Times, vol. 11, 2012.\\n[11]  P . Alston, \"Lethal robotic technologies: the implications for \\nhuman rights and international humanitarian law,\" JL Inf. & \\nSci., vol. 21, p. 35, 2011.\\n[12]  A. Young and M. Yung, \"Deniable password snatching: On the \\npossibility of evasive electronic espionage,\" in Security and \\nPrivacy, 1997. Proceedings., 1997 IEEE Symposium on, 1997, \\npp. 224-235.\\n[13]  D. Kirat, G. Vigna, and C. Kruegel, \"Barecloud: bare-metal \\nanalysis-based evasive malware detection,\" in 23rd USENIX \\nSecurity Symposium (USENIX Security 14), 2014, pp. 287-\\n301.\\n[14]  C. Bryant and R. Waters, \"Worker at Volkswagen plant killed in \\nrobot accident,\" in Finantial Times, ed, 2015.\\n[15]  J. Andreu-Perez, D. R. Leff, K. Shetty, A. Darzi, and G.-Z. \\nYang, \"Disparity in Frontal Lobe Connectivity on a Complex \\nBimanual Motor Task Aids in Classification of Operator Skill \\nLevel,\" Brain connectivity, vol. 6, pp. 375-388, 2016.\\n[16] J . Harrison, K. Izzetoglu, H. Ayaz, B. Willems, S. Hah, \\nU. Ahlstrom, et al., \"Cognitive workload and learning \\nassessment during the implementation of a next-generation \\nair traffic control technology using functional near-infrared \\nspectroscopy,\" IEEE Transactions on Human-Machine \\nSystems, vol. 44, pp. 429-440, 2014.[17]  A. J. Gonzalez and V. Barr, \"Validation and verification of \\nintelligent systems-what are they and how are they different?,\" \\nJournal of Experimental & Theoretical Artificial Intelligence, vol. \\n12, pp. 407-420, 2000.\\n[18]  S. Ratschan and Z. She, \"Safety verification of hybrid systems \\nby constraint propagation based abstraction refinement,\" in \\nInternational Workshop on Hybrid Systems: Computation and \\nControl, 2005, pp. 573-589.\\n[19]  E. Broadbent, R. Stafford, and B. MacDonald, \"Acceptance of \\nhealthcare robots for the older population: review and future \\ndirections,\" International Journal of Social Robotics, vol. 1, pp. \\n319-330, 2009.\\n[20]  C.-A. Smarr, A. Prakash, J. M. Beer, T. L. Mitzner, C. C. \\nKemp, and W. A. Rogers, \"Older adults’ preferences for and \\nacceptance of robot assistance for everyday living tasks,\" in \\nProceedings of the Human Factors and Ergonomics Society \\nAnnual Meeting, 2012, pp. 153-157.\\n[21]  R. C. O\\'Reilly and Y. Munakata, Computational explorations in \\ncognitive neuroscience: Understanding the mind by simulating \\nthe brain: MIT press, 2000.\\n[22]  G.-Z. Yang. (2017) Robotics and AI Driving the UK’s Industrial \\nStrategy. Ingenia. \\n[23] S. Inc, \"Artificial Intelligence (AI),\" 2016.\\n[24]  S. Farquhar. (2017). Changes in funding in the AI safety field. \\nAvailable: https://www.centreforeffectivealtruism.org/blog/\\nchanges-in-funding-in-the-ai-safety-field\\n[25] T. Reuters, \"Web of Science,\" 2012.\\n[26]  G. Scimago, \"SJR—SCImago Journal & Country Rank,\" ed, \\n2007.\\n[27]  B. Diallo and M. Lupu, \"Future Patent Search,\" in Current \\nChallenges in Patent Information Retrieval, ed: Springer Berlin \\nHeidelberg, 2017, pp. 433-455.\\n[28]  N. Chen, L. Christensen, K. Gallagher, R. Mate, and G. \\nRafert, \"Global Economic Impacts Associated with Artificial \\nIntelligence,\" Study, Analysis Group, Boston, MA, February, \\nvol. 25, 2016.\\n[29]  C. M. R. Christine Zhen-Wei Qiang, Kaoru Kimura, \"Economic \\nImpacts of Broadband,\" in The World Bank, ed, 2009.\\n[30]  N. Czernich, O. Falck, T. Kretschmer, and L. Woessmann, \\n\"Broadband Infrastructure and Economic Growth,\" Economic \\nJournal, vol. 121, pp. 505-532, May 2011.\\n[31]  J. Andreu-Perez, C. C. Poon, R. D. Merrifield, S. T. Wong, and \\nG.-Z. Yang, \"Big data for health,\" IEEE journal of biomedical \\nand health informatics, vol. 19, pp. 1193-1208, 2015.˘.'),\n",
       " Document(metadata={'source': 'data/AI_Robotics.pdf', 'page': 51}, page_content='45 // Artificial Intelligence and Robotics\\nREFERENCES\\n[32]  D. Ravi, C. Wong, F. Deligianni, M. Berthelot, J. Andreu-Perez, \\nB. Lo, et al., \"Deep Learning for Health Informatics,\" IEEE \\nJournal of Biomedical and Health Informatics, vol. 21, pp. \\n4-21, Jan 2017.\\n[33]  Y. LeCun, Y. Bengio, and G. Hinton, \"Deep learning,\" Nature, \\nvol. 521, pp. 436-444, 2015.\\n[34]  L. A. Zadeh, \"Fuzzy logic= computing with words,\" Fuzzy \\nSystems, IEEE Transactions on, vol. 4, pp. 103-111, 1996.\\n[35]  D. B. Fogel, Evolutionary computation: toward a new \\nphilosophy of machine intelligence vol. 1: John Wiley & Sons, \\n2006.\\n[36]  L. Breiman, \"Statistical modeling: The two cultures (with \\ncomments and a rejoinder by the author),\" Statistical science, \\nvol. 16, pp. 199-231, 2001.\\n[37]  S. Senn, \"Trying to be precise about vagueness,\" Statistics in \\nmedicine, vol. 26, p. 1417, 2007.\\n[38]  W. S. McCulloch and W. Pitts, \"A logical calculus of the ideas \\nimmanent in nervous activity,\" The bulletin of mathematical \\nbiophysics, vol. 5, pp. 115-133, 1943.\\n[39]  F. Rosenblatt, \"The perceptron: A probabilistic model \\nfor information storage and organization in the brain,\" \\nPsychological review, vol. 65, p. 386, 1958.\\n[40]  P . Werbos, \"Beyond regression: new tools for prediction and \\nanalysis in the behavioral sciences [Ph. D. thesis] Cambridge,\" \\nMass, USA: Hardward University, 1974.\\n[41]  K. Hornik, M. Stinchcombe, and H. White, \"Multilayer \\nfeedforward networks are universal approximators,\" Neural \\nnetworks, vol. 2, pp. 359-366, 1989.\\n[42]  D. E. Rumelhart, G. E. Hinton, and R. J. Williams, \"Learning \\nrepresentations by back-propagating errors,\" Cognitive \\nmodeling, vol. 5, p. 1, 1988.\\n[43]  R. J. Williams and D. Zipser, \"A learning algorithm for \\ncontinually running fully recurrent neural networks,\" Neural \\ncomputation, pp. 270-280 1989.\\n[44]  S. Hochreiter and J. Schmidhuber, \"Long short-term memory,\" \\nNeural computation, vol. 9, pp. 1735-1780, 1997.\\n[45]  Y. LeCun, L. Bottou, Y. Bengio, and P . Haffner, \"Gradient-\\nbased learning applied to document recognition,\" Proceedings \\nof the IEEE, vol. 86, pp. 2278-2324, 1998.\\n[46]  G. E. Hinton, S. Osindero, and Y.-W. Teh, \"A fast learning \\nalgorithm for deep belief nets,\" Neural computation, vol. 18, \\npp. 1527-1554, 2006.\\n[47]  G. E. Hinton and T. J. Sejnowski, \"Learning and releaming in \\nBoltzmann machines,\" Parallel Distrilmted Processing, vol. 1, \\n1986.[48]  A. Krizhevsky, I. Sutskever, and G. E. Hinton, \"Imagenet \\nclassification with deep convolutional neural networks,\" in \\nAdvances in neural information processing systems, 2012, pp. \\n1097-1105.\\n[49]  S. Ioffe and C. Szegedy, \"Batch normalization: Accelerating \\ndeep network training by reducing internal covariate shift,\" \\narXiv preprint arXiv:1502.03167, 2015.\\n[50]  D. Silver, A. Huang, C. J. Maddison, A. Guez, L. Sifre, G. Van \\nDen Driessche, et al., \"Mastering the game of Go with deep \\nneural networks and tree search,\" Nature, vol. 529, p. 484, \\n2016.\\n[51]  M. Moravcík, M. Schmid, N. Burch, V. Lisý, D. Morrill, N. Bard, \\net al., \"DeepStack: Expert-Level Artificial Intelligence in No-\\nLimit Poker,\" arXiv preprint arXiv:1701.01724, 2017.\\n[52]  C. Rogers, \"Google Sees Self-Driving Cars on Road within \\nFive Years,\" Wall Street Journal, 2015.\\n[53]  D. Floreano and R. J. Wood, \"Science, technology and the \\nfuture of small autonomous drones,\" Nature, vol. 521, pp. \\n460-466, 2015.\\n[54]  Z. Chen, X. Jia, A. Riedel, and M. Zhang, \"A bio-inspired \\nswimming robot,\" in Robotics and Automation (ICRA), 2014 \\nIEEE International Conference on, 2014, pp. 2564-2564.\\n[55]  Y. Ohmura and Y. Kuniyoshi, \"Humanoid robot which can lift \\na 30kg box by whole body contact and tactile feedback,\" in \\nIntelligent Robots and Systems, 2007. IROS 2007. IEEE/RSJ \\nInternational Conference on, 2007, pp. 1136-1141.\\n[56]  Z. Kappassov, J.-A. Corrales, and V. Perdereau, \"Tactile \\nsensing in dexterous robot hands—Review,\" Robotics and \\nAutonomous Systems, vol. 74, pp. 195-220, 2015.\\n[57]  H. Arisumi, S. Miossec, J.-R. Chardonnet, and K. Yokoi, \\n\"Dynamic lifting by whole body motion of humanoid robots,\" in \\nIntelligent Robots and Systems, 2008. IROS 2008. IEEE/RSJ \\nInternational Conference on, 2008, pp. 668-675.\\n[58]  M. Asada, \"Towards artificial empathy,\" International Journal of \\nSocial Robotics, vol. 7, pp. 19-33, 2015.\\n[59]  L. Zhang, M. Jiang, D. Farid, and M. A. Hossain, \"Intelligent \\nfacial emotion recognition and semantic-based topic detection \\nfor a humanoid robot,\" Expert Systems with Applications, vol. \\n40, pp. 5160-5168, 2013.\\n[60]  N. Mavridis, \"A review of verbal and non-verbal human–robot \\ninteractive communication,\" Robotics and Autonomous \\nSystems, vol. 63, pp. 22-35, 2015.\\n[61]  T. Kruse, A. K. Pandey, R. Alami, and A. Kirsch, \"Human-\\naware robot navigation: A survey,\" Robotics and Autonomous \\nSystems, vol. 61, pp. 1726-1743, 2013.ˇ'),\n",
       " Document(metadata={'source': 'data/AI_Robotics.pdf', 'page': 52}, page_content='Artificial Intelligence and Robotics  // 46\\n[62]  K. Mochizuki, S. Nishide, H. G. Okuno, and T. Ogata, \\n\"Developmental human-robot imitation learning of drawing \\nwith a neuro dynamical system,\" in Systems, Man, and \\nCybernetics (SMC), 2013 IEEE International Conference on, \\n2013, pp. 2336-2341.\\n[63]  P .-Y. Oudeyer, \"Socially guided intrinsic motivation for robot \\nlearning of motor skills,\" Autonomous Robots, vol. 36, pp. \\n273-294, 2014.\\n[64]  M. T. Chan, R. Gorbet, P . Beesley, and D. Kulic, \"Curiosity-\\nBased Learning Algorithm for Distributed Interactive Sculptural \\nSystems,\" in Intelligent Robots and Systems (IROS), 2015 \\nIEEE/RSJ International Conference on, 2015, pp. 3435-3441.\\n[65]  J. McCarthy, Programs with common sense: RLE and MIT \\nComputation Center, 1960.\\n[66]  H. Murase and S. K. Nayar, \"Visual Learning and Recognition \\nof 3-D Objects from Appearance,\" International Journal of \\nComputer Vision, vol. 14, pp. 5-24, Jan 1995.\\n[67]  P . Viola and M. Jones, \"Robust real-time face detection,\" \\nEighth IEEE International Conference on Computer Vision, pp. \\n747-747, 2001.\\n[68]  A. Esteva, B. Kuprel, R. A. Novoa, J. Ko, S. M. Swetter, H. M. \\nBlau, et al., \"Dermatologist-level classification of skin cancer \\nwith deep neural networks,\" Nature, vol. 542, pp. 115-+, Feb \\n2 2017.\\n[69]  R. Fergus, P . Perona, and A. Zisserman, \"Object class \\nrecognition by unsupervised scale-invariant learning,\" 2003 \\nIEEE Computer Society Conference on Computer Vision and \\nPattern Recognition, pp. 264-271, 2003.\\n[70]  T. Leung and J. Malik, \"Representing and recognizing the \\nvisual appearance of materials using three-dimensional \\ntextons,\" International Journal of Computer Vision, vol. 43, pp. \\n29-44, 2001.\\n[71]  T. R. Society, \"Machine learning:  the power and promise of \\ncomputers that learn by example,\" ed. The Royal Society, \\n2017.\\n[72]  N. B. Anders Sandberg, \"Whole Brain Emulation: \\nA Roadmap,\" Future of Humanity Institute, Oxford \\nUniversity2008.\\n[73]  M. Colombo, \"Why build a virtual brain? Large-scale neural \\nsimulations as jump start for cognitive computing,\" Journal of \\nExperimental and Theoretical Artificial Intelligence, vol. 29, pp. \\n361-370, 2017.\\n[74]  P . Hankins, \"Trying to simulate the human brain is a waste of \\nenergy,\" E. Lake, Ed., ed, 2017.[75]  A. Prieto, B. Prieto, E. M. Ortigosa, E. Ros, F. Pelayo, J. \\nOrtega, et al., \"Neural networks: An overview of early research, \\ncurrent frameworks and new challenges,\" Neurocomputing, \\nvol. 214, pp. 242-268, Nov 19 2016.\\n[76]  D. Hémous and M. Olsen, \"The Rise of the Machines: \\nAutomation, Horizontal Innovation and Income Inequality,\" \\n2016.\\n[77]  M. E. Virgillito, \"Rise of the robots: technology and the threat \\nof a jobless future,\" Labor History, vol. 58, pp. 240-242, 2017.\\n[78]  T. E. P . s. L. A. Committee, \"European Civil Law Rules in \\nRobotics,\" 2016.ˇ'),\n",
       " Document(metadata={'source': 'data/AI_Robotics.pdf', 'page': 53}, page_content='The impact of robotics and AI will affect not only \\nmanufacturing, transport and healthcare, but also jobs \\nin agrifood, logistics, security, retail, and construction. \\nIt is important to assess the economic impact and \\nunderstand the social, legal and ethical issues of \\nrobotics and AI in order to maximise the benefits of \\nthese technologies while mitigating adverse effects. \\nEstablishing our lead in robotics and AI is an opportunity \\nthat the UK cannot afford to miss. The future lies in our \\ncoordinated effort to establish our niche and leverage the \\nsignificant strengths we already have, and expand upon \\nthose areas that are strategic to the UK.\\n// Artificial Intelligence  and Robotics    '),\n",
       " Document(metadata={'source': 'data/AI_Robotics.pdf', 'page': 54}, page_content=' Artificial Intelligence and Robotics //\\n'),\n",
       " Document(metadata={'source': 'data/AI_Robotics.pdf', 'page': 55}, page_content='Artiﬁcal Intelligence and Machine Learningwww.ukras.org')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Javier Andreu Perez, Fani Deligianni, Daniele Ravi and Guang-Zhong Yang  Artiﬁcial Intelligence and \n",
      "{'source': 'data/AI_Robotics.pdf', 'page': 0}\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content[0:100])\n",
    "print(docs[0].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set OpenAI API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0, max_tokens=150) # using gpt-4o-mini for low resource models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize Vector Store and Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "vectorstore = FAISS.from_documents(documents=splits, embedding=OpenAIEmbeddings(model='text-embedding-3-small'))\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Built-in Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.retrieval import create_retrieval_chain\n",
    "from langchain.chains.combine_documents.stuff import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, reply with \"\n",
    "    \"Data Not Available. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "# \"You are a helpful assistant that answers questions based on the given context.\"\n",
    "# \"If the answer is not explicitly stated in the context, reply with 'Data Not Available'\"\n",
    "# \"answer concise.\"\n",
    "# \"\\n\\n\"\n",
    "# \"{context}\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_tokens : 626, total_cost : 0.00013394999999999998\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Robotics is a field that combines advances in mechatronics, electrical engineering, and computing to develop machines with sophisticated sensorimotor functions, allowing them to adapt to changing environments. It involves the integration of robots into existing environments, enabling them to perform specialized autonomous tasks such as navigating, manipulating objects, and collaborating. The goal is to optimize the level of autonomy through learning and enhance the robots' ability to perceive, plan, and execute tasks.\""
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PDF included Q&A\n",
    "with get_openai_callback() as cb:\n",
    "    results = rag_chain.invoke({\"input\": \"What is robotics?\"})\n",
    "print(f\"total_tokens : {cb.total_tokens}, total_cost : {cb.total_cost}\")\n",
    "results['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_tokens : 612, total_cost : 0.0001314\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Robotics is a field that builds on advances in mechatronics, electrical engineering, and computing to develop increasingly sophisticated sensorimotor functions that enable machines to adapt to their ever-changing environment. It involves the integration of machines into existing environments, allowing for autonomy in perceiving, planning, and executing tasks such as manipulating, navigating, and collaborating. Robotics aims to optimize the level of autonomy through learning and includes applications in various specialized autonomous tasks.'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PDF included Q&A\n",
    "with get_openai_callback() as cb:\n",
    "    results = rag_chain.invoke({\"input\": \"What is robotics?\"})\n",
    "print(f\"total_tokens : {cb.total_tokens}, total_cost : {cb.total_cost}\")\n",
    "results['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_tokens : 646, total_cost : 9.87e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Data Not Available.'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with get_openai_callback() as cb:\n",
    "    results = rag_chain.invoke({\"input\": \"Can you tell me what is Mechanical Engineering?\"})\n",
    "print(f\"total_tokens : {cb.total_tokens}, total_cost : {cb.total_cost}\")\n",
    "results['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_tokens : 920, total_cost : 0.0001713\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\"Artificial Intelligence and the Big Brain\" refers to the efforts to simulate the human brain\\'s complexity and dynamics through advanced computational models. Projects like the Blue Brain Project aim to replicate brain functions to enhance our understanding of intelligence and consciousness. However, there is ongoing debate about whether these simulations can truly emulate conscious, intelligent behavior, given our limited understanding of the brain\\'s workings.'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with get_openai_callback() as cb:\n",
    "    results = rag_chain.invoke({\"input\": \"explain the ARTIFICIAL INTELLIGENCE AND THE BIG BRAIN\"})\n",
    "print(f\"total_tokens : {cb.total_tokens}, total_cost : {cb.total_cost}\")\n",
    "results['answer']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Custom Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token Used :: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    print(f\"Token Used :: {num_tokens}\")\n",
    "    return num_tokens\n",
    "\n",
    "num_tokens_from_string(\"testing word count\", \"cl100k_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "def get_answer_from_llm(question, context):\n",
    "    client = OpenAI()\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        max_tokens=150,\n",
    "        temperature=0,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that answers questions based on the given context. If the answer is not explicitly stated in the context, reply with 'Data Not Available'.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Context: {context}\\n\\nQuestion: {question}\"}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "import numpy as np\n",
    "\n",
    "def process_data_to_vectorstore(documents):\n",
    "    embeddings = OpenAIEmbeddings(model='text-embedding-3-small')\n",
    "    \n",
    "    # embedding_size = 1536\n",
    "    # index = faiss.IndexFlatL2(embedding_size)\n",
    "\n",
    "    # vector_store = FAISS(\n",
    "    #     embedding_function=embeddings,\n",
    "    #     index=index,\n",
    "    #     docstore=InMemoryDocstore(),\n",
    "    #     index_to_docstore_id={}\n",
    "    # )\n",
    "\n",
    "    # texts = [doc.page_content for doc in documents]\n",
    "    # metadata = [doc.metadata for doc in documents]\n",
    "    # vector_store.add_texts(texts, metadata)\n",
    "    \n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    texts = text_splitter.split_documents(documents)\n",
    "    vector_store = FAISS.from_documents(documents=texts, embedding=embeddings)\n",
    "    return vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_answer_confidence(question, docs, answer):\n",
    "    question_lower = question.lower()\n",
    "    for doc in docs:\n",
    "        if question_lower in doc.lower():\n",
    "            return doc.strip()\n",
    "    if len(answer) < 10: # already set the response \"Data Not Available\" in the prompt\n",
    "        return \"Data Not Available\"\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loaded_document(file_path):\n",
    "    loader = PyPDFLoader(file_path)\n",
    "    documents = loader.load()\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_chain(pdf_file,questions):\n",
    "    documents = get_loaded_document(pdf_file)\n",
    "    vector_store = process_data_to_vectorstore(documents)\n",
    "    answers = {}\n",
    "    for question in questions:\n",
    "        docs = vector_store.similarity_search(query=question, k=3)\n",
    "        context = \" \".join([doc.page_content for doc in docs])\n",
    "        num_tokens_from_string(context, \"cl100k_base\")\n",
    "        generated_response = get_answer_from_llm(question, context)\n",
    "        final_answer = check_answer_confidence(question, context, generated_response)\n",
    "        answers[question] = final_answer\n",
    "    return answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = ['what is robotics', 'explain the ARTIFICIAL INTELLIGENCE AND THE BIG BRAIN', 'Can you tell me what is Mechanical Engineering?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token Used :: 275\n",
      "Token Used :: 579\n",
      "Token Used :: 396\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'what is robotics': \"Robotics is the field that builds on advances in mechatronics, electrical engineering, and computing to develop increasingly sophisticated sensorimotor functions in machines. These functions enable machines to adapt to their ever-changing environment. Robotics involves the integration of machines into existing environments, allowing for greater autonomy in tasks such as perceiving, planning, and executing actions like manipulating, navigating, and collaborating. The convergence of AI and robotics aims to optimize the level of autonomy through learning, enhancing the machines' ability to predict future outcomes in various interactions.\",\n",
       " 'explain the ARTIFICIAL INTELLIGENCE AND THE BIG BRAIN': 'The section titled \"ARTIFICIAL INTELLIGENCE AND THE BIG BRAIN\" discusses the advancements in simulating the human brain and the implications for artificial intelligence (AI). It highlights that creating a computer as fast and complex as the human brain is becoming increasingly feasible, with several large-scale brain simulations aimed at replicating cortical dynamics observed in neuroscience studies. These simulations are intended to validate cognitive theories and hypotheses.\\n\\nA significant concern raised is whether these simulations could lead to the emergence of a conscious and intelligent entity, and how we might detect such consciousness or intelligence without a comprehensive understanding of what these concepts entail.\\n\\nThe timeline provided outlines key projects and initiatives in brain simulation and AI development:\\n\\n- **2005**: The Blue Brain Project, a Swiss initiative focused',\n",
       " 'Can you tell me what is Mechanical Engineering?': 'Data Not Available.'}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers = custom_chain(file_path,questions)\n",
    "answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_two = ['what is the use of robotics', 'who is messi', 'Can you tell me what is Chemical Engineering?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token Used :: 400\n",
      "Token Used :: 372\n",
      "Token Used :: 560\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'what is the use of robotics': 'The use of robotics includes the following objectives as defined by the US military: \\n\\n1) Increase knowledge abilities in operations’ theatres.\\n2) Reduce the amount of charge carried by the soldier.\\n3) Improve logistics capacity.\\n4) Facilitate movement and manoeuvring.\\n5) Increase the protection of forces.\\n\\nAdditionally, robotics is developing increasingly sophisticated sensorimotor functions that allow machines to adapt to their environment, and they are becoming more autonomous, capable of interacting, executing tasks, and making complex decisions.',\n",
       " 'who is messi': 'Data Not Available.',\n",
       " 'Can you tell me what is Chemical Engineering?': 'Data Not Available.'}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers = custom_chain(file_path,questions_two)\n",
    "answers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-agent-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
